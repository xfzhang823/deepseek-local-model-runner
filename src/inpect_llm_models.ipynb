{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2065fa2e",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ceec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def show_scrollable(content, height=\"300px\"):\n",
    "    \"\"\"\n",
    "    Display content in a scrollable box in Jupyter Notebook.\n",
    "\n",
    "    Args:\n",
    "        content: Content to display (string, list, dict, or any printable object)\n",
    "        height: Height of the scrollable box (e.g., '300px', '500px', '50%')\n",
    "\n",
    "    Examples:\n",
    "        >>> # Display a long list\n",
    "        >>> show_scrollable([f\"Item {i}\" for i in range(100)])\n",
    "\n",
    "        >>> # Display a dictionary with custom height\n",
    "        >>> big_dict = {i: f\"Value {i}\" for i in range(50)}\n",
    "        >>> show_scrollable(big_dict, height='400px')\n",
    "\n",
    "        >>> # Display string output\n",
    "        >>> show_scrollable(\"Lorem ipsum...\\\\n\" * 50)\n",
    "    \"\"\"\n",
    "    out = widgets.Output(\n",
    "        layout={\n",
    "            \"height\": height,\n",
    "            \"overflow\": \"auto\",\n",
    "            \"border\": \"1px solid #ddd\",\n",
    "            \"padding\": \"5px\",\n",
    "        }\n",
    "    )\n",
    "    display(out)\n",
    "\n",
    "    with out:\n",
    "        if isinstance(content, (list, dict)):\n",
    "            pprint(content)\n",
    "        else:\n",
    "            print(content) if content is not None else print(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc70e6",
   "metadata": {},
   "source": [
    "# Inspecting DS R1 Qwen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31124c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2Config {\n",
      "  \"_name_or_path\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151643,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_mrope\": false,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "print(config)  # Full architecture details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae52d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "Qwen2ForCausalLM                                   [1, 2, 128, 128]          --\n",
       "├─Qwen2Model: 1-1                                  [1, 2, 128, 128]          --\n",
       "│    └─Embedding: 2-1                              [1, 128, 1536]            233,373,696\n",
       "│    └─Qwen2RotaryEmbedding: 2-2                   [1, 128, 128]             --\n",
       "│    └─ModuleList: 2-3                             --                        --\n",
       "│    │    └─Qwen2DecoderLayer: 3-1                 [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-2                 [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-3                 [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-4                 [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-5                 [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-6                 [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-7                 [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-8                 [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-9                 [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-10                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-11                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-12                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-13                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-14                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-15                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-16                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-17                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-18                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-19                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-20                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-21                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-22                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-23                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-24                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-25                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-26                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-27                [1, 128, 1536]            46,797,824\n",
       "│    │    └─Qwen2DecoderLayer: 3-28                [1, 128, 1536]            46,797,824\n",
       "│    └─Qwen2RMSNorm: 2-4                           [1, 128, 1536]            1,536\n",
       "├─Linear: 1-2                                      [1, 128, 151936]          233,373,696\n",
       "====================================================================================================\n",
       "Total params: 1,777,088,000\n",
       "Trainable params: 1,777,088,000\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.78\n",
       "====================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 907.41\n",
       "Params size (MB): 7108.35\n",
       "Estimated Total Size (MB): 8015.76\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "\n",
    "# Load models\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "summary(model, input_size=(1, 128), dtypes=[torch.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    # if \"layers\" in name and \"proj\" in name:\n",
    "    print(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d538ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2Config {\n",
      "  \"_name_or_path\": \"Qwen/Qwen1.5-1.8B\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151643,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5504,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "original_config = AutoConfig.from_pretrained(\"Qwen/Qwen1.5-1.8B\")\n",
    "print(original_config)  # Compare hidden_size, layers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9d445",
   "metadata": {},
   "source": [
    "## Inspect Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f18e3646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Layer: model.layers.0.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0300,  0.0226,  0.0251],\n",
      "        [-0.0177, -0.0050,  0.0713],\n",
      "        [-0.0033, -0.0170,  0.0043]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.0.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0645,  0.0148, -0.1377],\n",
      "        [ 0.0254, -0.0625,  0.0957],\n",
      "        [ 0.0068, -0.0386, -0.0035]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.0.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0123, -0.0309,  0.0085],\n",
      "        [ 0.0025, -0.0030,  0.0259],\n",
      "        [ 0.0214,  0.0449, -0.0035]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.0.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0015,  0.0013, -0.0114],\n",
      "        [-0.0214,  0.0020,  0.0044],\n",
      "        [ 0.0430,  0.0229, -0.0354]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.0.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0266,  0.0369, -0.0342],\n",
      "        [-0.0210, -0.0135, -0.0405],\n",
      "        [ 0.0566, -0.0588,  0.0315]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.0.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0603, -0.0179,  0.0378],\n",
      "        [ 0.0104,  0.0085,  0.0270],\n",
      "        [-0.0035,  0.0195,  0.0361]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.0.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0064, -0.0107,  0.0212],\n",
      "        [ 0.0330, -0.0011,  0.0017],\n",
      "        [-0.0187,  0.0300,  0.0574]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.0.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.1.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0005,  0.0057, -0.0159],\n",
      "        [-0.0295,  0.0113, -0.0129],\n",
      "        [ 0.0532, -0.0128,  0.0243]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.1.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0084, -0.0461,  0.0123],\n",
      "        [ 0.0371,  0.0181,  0.0071],\n",
      "        [-0.0149,  0.0830,  0.0215]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.1.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0232, -0.0292, -0.0019],\n",
      "        [-0.0031,  0.0065, -0.0422],\n",
      "        [-0.0444, -0.0132, -0.0148]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.1.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0146,  0.0160,  0.0330],\n",
      "        [-0.0148, -0.0791,  0.0255],\n",
      "        [ 0.0060,  0.0364,  0.0513]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.1.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0162,  0.0233, -0.0415],\n",
      "        [ 0.0015,  0.0139, -0.0022],\n",
      "        [ 0.0991,  0.0510, -0.0162]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.1.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0283, -0.0063,  0.0708],\n",
      "        [ 0.0063,  0.0037,  0.0126],\n",
      "        [-0.0437, -0.0128, -0.0049]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.1.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0063,  0.0026, -0.0933],\n",
      "        [-0.0332, -0.0021, -0.0320],\n",
      "        [ 0.0269,  0.0066, -0.0050]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.1.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.2.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0072,  0.0032,  0.0640],\n",
      "        [-0.0139, -0.0393, -0.0135],\n",
      "        [-0.0107, -0.0649, -0.0908]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.2.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 1.7944e-02,  5.6458e-03,  3.2471e-02],\n",
      "        [-1.4954e-03,  3.5889e-02,  4.7302e-03],\n",
      "        [ 1.7212e-02,  3.5400e-02, -6.7711e-05]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.2.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0143, -0.0591, -0.0874],\n",
      "        [-0.0023,  0.0114,  0.0099],\n",
      "        [-0.0055, -0.0214, -0.0037]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.2.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0022, -0.0664, -0.0364],\n",
      "        [ 0.0201, -0.0128,  0.0381],\n",
      "        [-0.0036,  0.0569, -0.0403]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.2.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0278,  0.0457, -0.0388],\n",
      "        [ 0.0430, -0.0204,  0.0117],\n",
      "        [ 0.0540, -0.0310, -0.0576]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.2.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0554,  0.0233,  0.0515],\n",
      "        [ 0.0025, -0.0588, -0.0334],\n",
      "        [-0.0991,  0.0393, -0.0264]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.2.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0211,  0.0188,  0.0552],\n",
      "        [ 0.0250, -0.0569, -0.0177],\n",
      "        [ 0.0127,  0.0097,  0.0430]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.2.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.3.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0190, -0.0003,  0.0381],\n",
      "        [ 0.0022,  0.0099,  0.0649],\n",
      "        [-0.0041,  0.0549,  0.0654]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.3.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0247, -0.0074, -0.0118],\n",
      "        [ 0.0037,  0.0227,  0.0172],\n",
      "        [-0.0236, -0.0096, -0.0322]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.3.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0413,  0.0388, -0.0229],\n",
      "        [ 0.0742, -0.0649, -0.0265],\n",
      "        [ 0.0649,  0.0645,  0.0138]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.3.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0106, -0.0126,  0.0265],\n",
      "        [ 0.0236, -0.0261, -0.0649],\n",
      "        [ 0.0026,  0.0356, -0.0459]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.3.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0508,  0.0459, -0.0532],\n",
      "        [-0.0018, -0.0126,  0.1011],\n",
      "        [ 0.0262,  0.0184,  0.0522]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.3.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0437, -0.0442,  0.0100],\n",
      "        [ 0.0466,  0.0469,  0.0493],\n",
      "        [ 0.0840, -0.0459, -0.0388]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.3.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-3.7842e-02,  5.2979e-02, -5.4932e-02],\n",
      "        [-1.8188e-02, -3.2959e-02, -2.4292e-02],\n",
      "        [-5.3467e-02, -6.4453e-02,  2.7061e-05]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.3.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.4.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0369, -0.0036,  0.0339],\n",
      "        [-0.0212,  0.0226, -0.0137],\n",
      "        [ 0.0135, -0.0175, -0.0454]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.4.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0205, -0.0278,  0.0129],\n",
      "        [ 0.0339,  0.0194,  0.0160],\n",
      "        [ 0.0041,  0.0107,  0.0298]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.4.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0171, -0.0364,  0.0073],\n",
      "        [ 0.0027,  0.1328, -0.0376],\n",
      "        [ 0.0144,  0.0544, -0.0168]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.4.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0320, -0.0134,  0.0160],\n",
      "        [-0.0613,  0.0522, -0.0110],\n",
      "        [-0.0522,  0.1245, -0.0410]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.4.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0879, -0.0022, -0.0498],\n",
      "        [ 0.0056,  0.0518, -0.0234],\n",
      "        [-0.0579, -0.0325, -0.0354]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.4.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0234,  0.0615,  0.0189],\n",
      "        [ 0.0116, -0.0275,  0.0236],\n",
      "        [-0.0071,  0.0062, -0.0104]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.4.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0192,  0.0020,  0.0322],\n",
      "        [-0.0079,  0.0302,  0.0410],\n",
      "        [ 0.0009,  0.0231, -0.0054]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.4.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.5.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-7.1049e-05,  5.8289e-03,  2.5513e-02],\n",
      "        [-6.1340e-03, -3.6865e-02, -1.1658e-02],\n",
      "        [-3.1738e-03,  1.5259e-03,  3.8818e-02]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.5.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0040, -0.0233,  0.0422],\n",
      "        [ 0.0018,  0.0019,  0.0042],\n",
      "        [-0.0032, -0.0476,  0.0178]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.5.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0115,  0.0864, -0.0212],\n",
      "        [ 0.0084,  0.0164,  0.0630],\n",
      "        [-0.0151, -0.0542, -0.0432]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.5.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0334,  0.0038,  0.0211],\n",
      "        [-0.0160,  0.0364, -0.0371],\n",
      "        [-0.0027,  0.0981,  0.0840]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.5.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0327, -0.0123, -0.0688],\n",
      "        [-0.0403, -0.0476, -0.0654],\n",
      "        [ 0.0430,  0.0198, -0.0400]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.5.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0258, -0.0094, -0.0562],\n",
      "        [ 0.0518,  0.0347, -0.0245],\n",
      "        [ 0.0051, -0.0124,  0.0288]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.5.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0074, -0.0123,  0.0767],\n",
      "        [-0.0256,  0.0095, -0.0305],\n",
      "        [-0.0320,  0.0791,  0.0383]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.5.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.6.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0047, -0.0166,  0.0226],\n",
      "        [-0.0051,  0.0674,  0.0366],\n",
      "        [ 0.0149,  0.0068, -0.0208]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.6.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0109,  0.0035, -0.0364],\n",
      "        [ 0.0124, -0.0226,  0.0442],\n",
      "        [ 0.0110, -0.0110,  0.0081]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.6.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0120,  0.1226,  0.0571],\n",
      "        [ 0.0077, -0.0664,  0.0168],\n",
      "        [-0.0095,  0.0026,  0.0260]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.6.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0031, -0.0262,  0.0452],\n",
      "        [-0.0020,  0.0278, -0.0859],\n",
      "        [-0.0330, -0.0383,  0.0913]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.6.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0942,  0.0130,  0.0845],\n",
      "        [-0.0101, -0.0066,  0.0057],\n",
      "        [-0.0332, -0.0245, -0.0400]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.6.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0728, -0.0515,  0.0510],\n",
      "        [-0.0148, -0.0055,  0.0283],\n",
      "        [-0.0052, -0.0192,  0.0091]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.6.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0223,  0.0011, -0.0106],\n",
      "        [-0.0488, -0.0291,  0.0018],\n",
      "        [ 0.0608, -0.0349, -0.0376]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.6.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.7.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0054, -0.0256, -0.0029],\n",
      "        [ 0.0138, -0.0547,  0.0171],\n",
      "        [ 0.0074,  0.0154, -0.0109]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.7.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0256,  0.0243, -0.0089],\n",
      "        [ 0.0505,  0.0038, -0.0037],\n",
      "        [-0.0068, -0.0057, -0.0278]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.7.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0479,  0.0850,  0.0139],\n",
      "        [ 0.0732, -0.0034,  0.0122],\n",
      "        [ 0.0034, -0.0366,  0.0352]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.7.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0801, -0.0461, -0.0430],\n",
      "        [-0.1104,  0.0413,  0.0669],\n",
      "        [-0.0330,  0.0281, -0.0630]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.7.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0302, -0.0293,  0.0240],\n",
      "        [ 0.0123,  0.0334, -0.0559],\n",
      "        [-0.0280, -0.0659, -0.0142]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.7.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0099, -0.0023,  0.0067],\n",
      "        [ 0.0464, -0.0400,  0.0034],\n",
      "        [ 0.0007,  0.0099,  0.0020]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.7.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0148, -0.0344, -0.0103],\n",
      "        [ 0.0107, -0.0728,  0.0277],\n",
      "        [ 0.0058,  0.0029,  0.0254]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.7.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.8.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0640,  0.0820,  0.0747],\n",
      "        [-0.0408, -0.0047, -0.1084],\n",
      "        [ 0.0596, -0.0737, -0.0254]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.8.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0161, -0.0239,  0.0040],\n",
      "        [-0.0129, -0.0211, -0.0098],\n",
      "        [-0.0110,  0.0030,  0.0035]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.8.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0015, -0.0505,  0.0061],\n",
      "        [-0.0003,  0.0240, -0.0835],\n",
      "        [-0.0002,  0.0225, -0.0120]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.8.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0232, -0.0179,  0.0315],\n",
      "        [ 0.0131,  0.0042,  0.0776],\n",
      "        [-0.1118, -0.0140, -0.0464]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.8.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0564,  0.0227,  0.0625],\n",
      "        [-0.0388,  0.0206, -0.0320],\n",
      "        [-0.0036,  0.0184,  0.0014]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.8.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0371, -0.0835,  0.0605],\n",
      "        [ 0.0146,  0.0359, -0.0015],\n",
      "        [-0.0437, -0.0031,  0.0356]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.8.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0635, -0.0479,  0.0201],\n",
      "        [-0.0284,  0.0630, -0.0510],\n",
      "        [ 0.0130, -0.0825,  0.0381]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.8.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.9.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0039,  0.0864, -0.0078],\n",
      "        [-0.0280,  0.0547, -0.0104],\n",
      "        [-0.0031, -0.0059,  0.0515]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.9.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0248, -0.0210, -0.0045],\n",
      "        [-0.0344, -0.0061,  0.0028],\n",
      "        [ 0.0161, -0.0229,  0.0107]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.9.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-2.2583e-02, -5.3711e-02,  1.3428e-02],\n",
      "        [ 6.4697e-03, -4.6387e-03,  1.7762e-05],\n",
      "        [-6.4087e-03,  5.2002e-02, -1.7090e-02]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.9.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0304, -0.0381,  0.0226],\n",
      "        [ 0.0933,  0.0483, -0.0625],\n",
      "        [-0.0344,  0.0217, -0.0025]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.9.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0057, -0.0112,  0.0228],\n",
      "        [-0.0065,  0.0123, -0.0356],\n",
      "        [ 0.0294,  0.0261,  0.0161]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.9.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0291, -0.0537,  0.0425],\n",
      "        [ 0.0029,  0.0476, -0.0250],\n",
      "        [ 0.0059, -0.0347,  0.0025]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.9.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0221,  0.0181, -0.0449],\n",
      "        [-0.0008,  0.0199, -0.0294],\n",
      "        [-0.0359, -0.0137, -0.1021]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.9.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.10.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0049, -0.0034, -0.0193],\n",
      "        [ 0.0221, -0.0059, -0.0106],\n",
      "        [-0.0063,  0.0330, -0.0184]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.10.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0264, -0.0040,  0.0071],\n",
      "        [ 0.0074, -0.0123, -0.0117],\n",
      "        [-0.0150, -0.0149,  0.0153]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.10.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0087,  0.0840,  0.0271],\n",
      "        [ 0.0469, -0.0025, -0.0164],\n",
      "        [-0.0058, -0.0254, -0.0142]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.10.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0315, -0.0023,  0.0011],\n",
      "        [-0.0422,  0.0038, -0.0033],\n",
      "        [-0.0583, -0.0103, -0.0581]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.10.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0349,  0.0635,  0.0153],\n",
      "        [ 0.0547, -0.0554, -0.0635],\n",
      "        [ 0.0317, -0.0240, -0.0135]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.10.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0491, -0.0219, -0.0332],\n",
      "        [-0.0208,  0.0547, -0.0369],\n",
      "        [-0.0040,  0.0110,  0.0239]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.10.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0004, -0.0322, -0.0112],\n",
      "        [-0.0742,  0.0145,  0.0415],\n",
      "        [ 0.0237, -0.0165,  0.0282]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.10.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.11.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0286, -0.0160,  0.0161],\n",
      "        [ 0.0164,  0.0236, -0.0165],\n",
      "        [-0.0047,  0.0054,  0.0060]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.11.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0210, -0.0204,  0.0081],\n",
      "        [-0.0057, -0.0050, -0.0047],\n",
      "        [ 0.0022, -0.0166,  0.0045]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.11.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0068, -0.0037,  0.0104],\n",
      "        [ 0.0012, -0.0270, -0.0260],\n",
      "        [-0.0586,  0.0366, -0.0156]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.11.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0070, -0.0143, -0.0099],\n",
      "        [ 0.0136,  0.0308,  0.0811],\n",
      "        [ 0.0703, -0.0021,  0.0654]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.11.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0527, -0.0359,  0.0413],\n",
      "        [-0.0625, -0.0096,  0.0098],\n",
      "        [-0.0415, -0.0154,  0.0140]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.11.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0152,  0.0874,  0.0369],\n",
      "        [-0.0420, -0.0117, -0.0334],\n",
      "        [-0.0107, -0.0005,  0.0486]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.11.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0091, -0.0315, -0.0160],\n",
      "        [ 0.0635, -0.0015,  0.0425],\n",
      "        [-0.0398, -0.0447,  0.0079]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.11.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.12.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0112,  0.0123,  0.0003],\n",
      "        [ 0.0068,  0.0466, -0.0034],\n",
      "        [-0.0176,  0.0244, -0.0310]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.12.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0033,  0.0065,  0.0032],\n",
      "        [-0.0029, -0.0092,  0.0253],\n",
      "        [-0.0102,  0.0131,  0.0211]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.12.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0027, -0.0187, -0.0170],\n",
      "        [-0.0006,  0.0114, -0.0361],\n",
      "        [-0.0011, -0.0488,  0.0415]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.12.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0009,  0.0026,  0.0713],\n",
      "        [-0.0654,  0.0156, -0.0063],\n",
      "        [ 0.0090,  0.0019, -0.0493]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.12.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0913,  0.0150,  0.0459],\n",
      "        [ 0.0439, -0.0162,  0.0312],\n",
      "        [-0.0177,  0.0613,  0.0352]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.12.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0211,  0.0085, -0.0210],\n",
      "        [-0.0015,  0.0270,  0.0330],\n",
      "        [ 0.0491,  0.0046, -0.0270]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.12.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0417,  0.0374, -0.0269],\n",
      "        [-0.0153, -0.0048,  0.0532],\n",
      "        [-0.0439, -0.0016, -0.0209]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.12.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.13.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0255,  0.0225, -0.0024],\n",
      "        [ 0.0261,  0.0019,  0.0011],\n",
      "        [ 0.0152,  0.0032,  0.0635]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.13.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0074,  0.0092,  0.0060],\n",
      "        [ 0.0198, -0.0114, -0.0166],\n",
      "        [-0.0012, -0.0019, -0.0096]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.13.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0205, -0.0186,  0.0139],\n",
      "        [-0.0275, -0.0228, -0.0513],\n",
      "        [-0.0052,  0.0275, -0.0095]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.13.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0052,  0.0146, -0.0034],\n",
      "        [ 0.0226, -0.0708, -0.0381],\n",
      "        [ 0.0110,  0.0991,  0.0645]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.13.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0415, -0.1235,  0.0732],\n",
      "        [-0.0574,  0.0786, -0.0126],\n",
      "        [-0.0291, -0.0552,  0.0254]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.13.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0104,  0.0510,  0.0068],\n",
      "        [-0.0515, -0.0430,  0.0216],\n",
      "        [-0.0422, -0.0297, -0.0049]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.13.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0330,  0.0234, -0.0208],\n",
      "        [ 0.0149, -0.0062, -0.0947],\n",
      "        [-0.0013,  0.0064, -0.0093]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.13.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.14.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0083,  0.0228,  0.0102],\n",
      "        [-0.0028,  0.0277,  0.0017],\n",
      "        [ 0.0150,  0.0036, -0.0028]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.14.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0320, -0.0084, -0.0015],\n",
      "        [-0.0001,  0.0058, -0.0036],\n",
      "        [-0.0141,  0.0012, -0.0005]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.14.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0080, -0.0098, -0.0107],\n",
      "        [ 0.0120, -0.0082,  0.0195],\n",
      "        [-0.0559,  0.0315, -0.0312]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.14.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0276, -0.0019,  0.0322],\n",
      "        [ 0.0237,  0.0112,  0.0245],\n",
      "        [ 0.0840, -0.0053, -0.0437]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.14.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0938,  0.0437,  0.0603],\n",
      "        [-0.0430,  0.0405, -0.0260],\n",
      "        [-0.0270, -0.0391,  0.0815]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.14.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0117,  0.0212, -0.0052],\n",
      "        [-0.0598, -0.0310, -0.0254],\n",
      "        [ 0.0265,  0.0566,  0.0459]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.14.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0020,  0.0132,  0.0327],\n",
      "        [-0.0294, -0.0327,  0.0874],\n",
      "        [-0.0374, -0.0337,  0.0245]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.14.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.15.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0405,  0.0215, -0.0347],\n",
      "        [ 0.0142, -0.0154,  0.0107],\n",
      "        [ 0.0188,  0.0708, -0.0052]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.15.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0311,  0.0432,  0.0082],\n",
      "        [-0.0679, -0.0115,  0.0102],\n",
      "        [-0.0182, -0.0060, -0.0175]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.15.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0161, -0.0183, -0.0540],\n",
      "        [-0.0231, -0.0261,  0.0206],\n",
      "        [ 0.0356, -0.0610,  0.0199]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.15.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0113, -0.0019, -0.0209],\n",
      "        [ 0.0204,  0.0356,  0.0435],\n",
      "        [-0.0898,  0.0400,  0.0243]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.15.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0337,  0.0374,  0.0162],\n",
      "        [-0.0364,  0.0518,  0.0310],\n",
      "        [-0.0064,  0.0444,  0.0752]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.15.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0151,  0.0045, -0.0032],\n",
      "        [-0.0359, -0.0386,  0.0400],\n",
      "        [-0.0376, -0.1035, -0.0004]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.15.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0021, -0.0099, -0.0723],\n",
      "        [ 0.0132, -0.0503, -0.0903],\n",
      "        [ 0.0325,  0.0576, -0.0415]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.15.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.16.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0292,  0.0189, -0.0071],\n",
      "        [ 0.0219,  0.0109, -0.0099],\n",
      "        [ 0.0310, -0.0225,  0.0181]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.16.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 9.5215e-03,  2.4719e-03,  9.5215e-03],\n",
      "        [-4.8584e-02, -1.1536e-02,  1.1902e-02],\n",
      "        [-1.3489e-02, -1.4832e-02, -1.1802e-05]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.16.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0014,  0.0208,  0.0122],\n",
      "        [ 0.0234, -0.0114,  0.0069],\n",
      "        [ 0.0889, -0.0211,  0.0253]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.16.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0223, -0.0334, -0.0068],\n",
      "        [ 0.0137, -0.0179, -0.0991],\n",
      "        [-0.0192, -0.0133,  0.0464]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.16.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0869,  0.0581,  0.0669],\n",
      "        [-0.0165,  0.0309,  0.0396],\n",
      "        [-0.0014, -0.0054,  0.0237]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.16.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0361, -0.0549, -0.0420],\n",
      "        [-0.0229,  0.0601, -0.0386],\n",
      "        [ 0.0422, -0.1025, -0.0747]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.16.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-2.8320e-02, -2.2583e-02, -2.8320e-02],\n",
      "        [-8.3496e-02, -3.7354e-02, -1.8555e-02],\n",
      "        [ 6.4850e-05,  2.5513e-02,  3.5889e-02]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.16.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.17.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0630,  0.0415,  0.0193],\n",
      "        [-0.0300,  0.0189,  0.0417],\n",
      "        [ 0.0302,  0.0161, -0.0422]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.17.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0194, -0.0024,  0.0028],\n",
      "        [-0.0057,  0.0172,  0.0190],\n",
      "        [-0.0068, -0.0177, -0.0108]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.17.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0002, -0.0300, -0.0216],\n",
      "        [-0.0036, -0.1191, -0.0283],\n",
      "        [ 0.0092, -0.1108, -0.0432]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.17.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0142,  0.0271, -0.0085],\n",
      "        [ 0.0535, -0.0688, -0.0253],\n",
      "        [-0.0493,  0.0248, -0.1270]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.17.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0344, -0.0069,  0.0175],\n",
      "        [ 0.0055,  0.0432,  0.0532],\n",
      "        [ 0.0233,  0.0085,  0.0151]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.17.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0356,  0.0391,  0.0688],\n",
      "        [-0.0115, -0.0562,  0.0242],\n",
      "        [-0.0277, -0.0280,  0.0405]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.17.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0040,  0.0159, -0.0004],\n",
      "        [ 0.0214,  0.0032,  0.0260],\n",
      "        [ 0.0105, -0.0654, -0.0165]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.17.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.18.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0630, -0.0317, -0.0084],\n",
      "        [-0.0542,  0.0129, -0.0309],\n",
      "        [ 0.0179,  0.0051,  0.0170]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.18.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0233, -0.0005,  0.0089],\n",
      "        [ 0.0281,  0.0054,  0.0074],\n",
      "        [ 0.0059, -0.0145, -0.0007]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.18.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0640,  0.0020,  0.0522],\n",
      "        [ 0.0923, -0.0247, -0.0688],\n",
      "        [-0.0713, -0.0083, -0.0081]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.18.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0229,  0.0014,  0.0150],\n",
      "        [ 0.0420, -0.0723,  0.0366],\n",
      "        [ 0.0996, -0.1436, -0.1533]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.18.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0020,  0.0398, -0.0391],\n",
      "        [-0.0150,  0.0432,  0.0118],\n",
      "        [ 0.0128,  0.0493, -0.0165]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.18.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-3.1006e-02,  9.9609e-02,  1.7700e-02],\n",
      "        [-6.3782e-03,  1.7822e-02,  2.2949e-02],\n",
      "        [ 1.9165e-02, -6.6895e-02,  7.2479e-05]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.18.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0177, -0.0344,  0.0025],\n",
      "        [ 0.0718, -0.0435, -0.0275],\n",
      "        [-0.0286,  0.0104, -0.0227]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.18.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.19.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0540,  0.0171,  0.0203],\n",
      "        [ 0.0400,  0.0089, -0.0135],\n",
      "        [-0.0030,  0.0322, -0.0044]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.19.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0081,  0.0136, -0.0064],\n",
      "        [-0.0003,  0.0019,  0.0002],\n",
      "        [ 0.0243,  0.0012,  0.0113]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.19.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0022,  0.0493, -0.0659],\n",
      "        [-0.0112, -0.0266, -0.0171],\n",
      "        [ 0.2910,  0.0388,  0.0244]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.19.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0248,  0.0447, -0.0410],\n",
      "        [-0.0033,  0.0139, -0.0879],\n",
      "        [-0.1719,  0.0781,  0.0444]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.19.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0466, -0.0092,  0.0483],\n",
      "        [-0.0378, -0.0298,  0.0518],\n",
      "        [ 0.0159,  0.0020,  0.2109]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.19.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0491, -0.0211, -0.0085],\n",
      "        [-0.0525, -0.0369,  0.0698],\n",
      "        [ 0.0097, -0.0154, -0.2734]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.19.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0608, -0.0067, -0.0288],\n",
      "        [ 0.0050, -0.0226,  0.0454],\n",
      "        [-0.0201,  0.0457, -0.0864]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.19.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.20.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0386,  0.0356,  0.0095],\n",
      "        [ 0.0146,  0.0493,  0.0349],\n",
      "        [-0.0588, -0.0479,  0.0220]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.20.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 3.1586e-03,  5.8289e-03,  4.3335e-03],\n",
      "        [ 6.1035e-05,  1.0742e-02, -2.4414e-03],\n",
      "        [-7.6904e-03,  1.8555e-02,  4.3945e-03]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.20.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0820, -0.0229, -0.0306],\n",
      "        [ 0.0203,  0.0845,  0.0098],\n",
      "        [-0.0014, -0.0640,  0.0133]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.20.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-1.8799e-02,  4.2969e-02, -4.9072e-02],\n",
      "        [-9.7168e-02,  7.1716e-03,  1.2695e-01],\n",
      "        [-1.0204e-04, -1.2695e-01, -1.8677e-02]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.20.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0327, -0.0177, -0.0527],\n",
      "        [ 0.0732, -0.0067, -0.0308],\n",
      "        [-0.0031,  0.0776, -0.0530]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.20.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0190,  0.0020,  0.0618],\n",
      "        [-0.0752,  0.0051,  0.0161],\n",
      "        [-0.0194,  0.0320, -0.0742]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.20.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0125,  0.0013,  0.0058],\n",
      "        [-0.0752,  0.0148,  0.0147],\n",
      "        [-0.0255,  0.0104,  0.0498]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.20.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.21.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0469, -0.0393,  0.0120],\n",
      "        [ 0.0311,  0.0435,  0.0037],\n",
      "        [ 0.0137,  0.0079, -0.0003]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.21.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0018, -0.0083, -0.0154],\n",
      "        [-0.0131, -0.0459,  0.0009],\n",
      "        [-0.0117,  0.0277, -0.0107]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.21.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.1157,  0.0281,  0.0135],\n",
      "        [-0.0035, -0.0356, -0.0435],\n",
      "        [ 0.0273,  0.0143, -0.0175]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.21.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0008,  0.0339, -0.0254],\n",
      "        [ 0.0312,  0.1201,  0.0820],\n",
      "        [ 0.0136,  0.0317, -0.0457]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.21.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0022,  0.0232,  0.0393],\n",
      "        [-0.0486, -0.0342,  0.0261],\n",
      "        [-0.0259, -0.0002,  0.0242]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.21.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0244, -0.0181,  0.0938],\n",
      "        [ 0.0322, -0.0067, -0.0295],\n",
      "        [ 0.0105, -0.0544,  0.0067]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.21.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0330, -0.0029, -0.0366],\n",
      "        [-0.0054,  0.0405, -0.0535],\n",
      "        [ 0.0347, -0.0245,  0.0053]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.21.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.22.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0059,  0.0261, -0.0225],\n",
      "        [ 0.0161,  0.0183, -0.0160],\n",
      "        [ 0.0251, -0.0118, -0.0369]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.22.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0038, -0.0025, -0.0020],\n",
      "        [-0.0060,  0.0288,  0.0077],\n",
      "        [-0.0067,  0.0093,  0.0110]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.22.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0297, -0.0420, -0.0072],\n",
      "        [-0.0110, -0.0115,  0.0236],\n",
      "        [-0.0249,  0.1953, -0.0220]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.22.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0459, -0.0051,  0.0102],\n",
      "        [-0.0154, -0.0405,  0.0942],\n",
      "        [ 0.0261,  0.0483, -0.0640]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.22.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0928, -0.0527, -0.0010],\n",
      "        [ 0.0087,  0.0117, -0.0408],\n",
      "        [ 0.0033,  0.0277, -0.0166]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.22.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0684,  0.0120, -0.0205],\n",
      "        [-0.0339, -0.0610, -0.0128],\n",
      "        [ 0.0003,  0.0210, -0.0081]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.22.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0173,  0.0221,  0.0014],\n",
      "        [-0.0383, -0.0165, -0.0415],\n",
      "        [-0.0303,  0.0210,  0.0022]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.22.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.23.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0237,  0.0242, -0.0134],\n",
      "        [ 0.0134, -0.0225, -0.0129],\n",
      "        [-0.0019,  0.0079,  0.0347]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.23.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0065, -0.0024,  0.0150],\n",
      "        [-0.0074, -0.0188,  0.0137],\n",
      "        [ 0.0051, -0.0039, -0.0040]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.23.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.1328,  0.0150, -0.0060],\n",
      "        [ 0.0159,  0.0120, -0.0015],\n",
      "        [-0.1396, -0.0005,  0.0009]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.23.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0265, -0.0320, -0.0118],\n",
      "        [ 0.0752, -0.0381,  0.0601],\n",
      "        [-0.0071, -0.0176,  0.0039]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.23.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0413, -0.0183,  0.0479],\n",
      "        [ 0.0074,  0.0356,  0.0718],\n",
      "        [-0.0396,  0.0291,  0.0040]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.23.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0354,  0.0615,  0.0237],\n",
      "        [ 0.0505, -0.0549, -0.0251],\n",
      "        [-0.0449, -0.0157, -0.0737]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.23.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0417, -0.0330,  0.0101],\n",
      "        [ 0.0525, -0.0430,  0.0107],\n",
      "        [ 0.0474,  0.0091, -0.0275]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.23.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.24.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[0.0024, 0.0109, 0.0066],\n",
      "        [0.0034, 0.0079, 0.0187],\n",
      "        [0.0107, 0.0067, 0.0284]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.24.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0063, -0.0447, -0.0042],\n",
      "        [-0.0079,  0.0242,  0.0010],\n",
      "        [-0.0027,  0.0255,  0.0232]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.24.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0267,  0.0747,  0.0239],\n",
      "        [ 0.0201,  0.0496, -0.0256],\n",
      "        [-0.0001, -0.0016, -0.0059]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.24.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0175, -0.0094,  0.0354],\n",
      "        [ 0.0698, -0.0025,  0.0530],\n",
      "        [-0.0496, -0.0295, -0.0879]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.24.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0019, -0.0231,  0.0664],\n",
      "        [ 0.0347,  0.0649,  0.0347],\n",
      "        [-0.0262, -0.0292,  0.0270]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.24.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0017, -0.0244, -0.0170],\n",
      "        [ 0.0613, -0.0320, -0.0645],\n",
      "        [ 0.0820,  0.0747,  0.0339]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.24.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0291,  0.0227, -0.0146],\n",
      "        [ 0.0693,  0.0166, -0.0098],\n",
      "        [ 0.0069, -0.0028, -0.0041]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.24.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.25.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0042, -0.0001,  0.0151],\n",
      "        [ 0.0069, -0.0466, -0.0339],\n",
      "        [-0.0117,  0.0493, -0.0250]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.25.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0048, -0.0010, -0.0095],\n",
      "        [-0.0029,  0.0292,  0.0062],\n",
      "        [-0.0043,  0.0034, -0.0238]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.25.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.1455, -0.1172,  0.0216],\n",
      "        [-0.0234, -0.0320, -0.0120],\n",
      "        [-0.1089,  0.0002,  0.0645]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.25.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0327,  0.0476,  0.0308],\n",
      "        [-0.0630, -0.0510,  0.0238],\n",
      "        [ 0.0112,  0.0537, -0.0713]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.25.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0083,  0.0192,  0.0091],\n",
      "        [ 0.0752,  0.0051, -0.0031],\n",
      "        [ 0.0659,  0.0593, -0.0261]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.25.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0236, -0.0194, -0.0315],\n",
      "        [-0.0366,  0.0308,  0.0479],\n",
      "        [ 0.0981,  0.0049, -0.0349]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.25.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0522,  0.0457, -0.0588],\n",
      "        [-0.0125, -0.0220, -0.0500],\n",
      "        [-0.0359, -0.0337,  0.0189]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.25.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.26.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0178, -0.0400, -0.0179],\n",
      "        [ 0.0150,  0.0199,  0.0091],\n",
      "        [ 0.0062, -0.0269,  0.0087]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.26.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0116, -0.0172,  0.0052],\n",
      "        [ 0.0025, -0.0034,  0.0072],\n",
      "        [ 0.0060,  0.0160, -0.0177]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.26.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0728,  0.0009, -0.0123],\n",
      "        [ 0.0347, -0.0170, -0.0009],\n",
      "        [ 0.1494, -0.0049,  0.0189]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.26.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0238,  0.0075,  0.0415],\n",
      "        [ 0.1021, -0.0535,  0.0325],\n",
      "        [ 0.0078,  0.0469, -0.0156]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.26.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0089,  0.0112, -0.0435],\n",
      "        [ 0.0791,  0.0089,  0.0486],\n",
      "        [-0.0026,  0.0620,  0.0079]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.26.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0461, -0.0195,  0.0806],\n",
      "        [-0.0544,  0.0115,  0.0122],\n",
      "        [ 0.0271,  0.0160, -0.0332]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.26.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0703, -0.0933,  0.0145],\n",
      "        [-0.0032, -0.0398,  0.0576],\n",
      "        [ 0.0210, -0.0145, -0.0309]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.26.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.27.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0032,  0.0564, -0.0186],\n",
      "        [ 0.0011,  0.0236, -0.0047],\n",
      "        [-0.0090,  0.0094,  0.0018]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.27.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0022, -0.0342,  0.0020],\n",
      "        [-0.0115, -0.0083, -0.0125],\n",
      "        [ 0.0086, -0.0041, -0.0225]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.27.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 8.1055e-02, -7.7637e-02,  1.2665e-03],\n",
      "        [-9.2773e-02, -1.3733e-02, -2.2217e-02],\n",
      "        [ 2.0874e-02, -8.3008e-03,  1.3888e-05]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.27.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0150,  0.0214, -0.0442],\n",
      "        [-0.0398, -0.0359,  0.0044],\n",
      "        [-0.0620,  0.0620,  0.0757]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.27.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.1118,  0.0111, -0.0679],\n",
      "        [-0.0400, -0.0168,  0.0040],\n",
      "        [ 0.0640,  0.0067, -0.0479]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.27.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0260,  0.0830,  0.0854],\n",
      "        [-0.0090, -0.0069, -0.0060],\n",
      "        [ 0.0376, -0.0270,  0.0786]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.27.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0447,  0.0231,  0.0383],\n",
      "        [ 0.0300, -0.0322, -0.0359],\n",
      "        [-0.0244, -0.0444, -0.0605]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.27.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: lm_head ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([151936, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0776,  0.0293, -0.0143],\n",
      "        [ 0.0518, -0.0444,  0.0284],\n",
      "        [ 0.0269, -0.0486, -0.0099]])\n",
      "\n",
      "=== Detailed First Layer Inspection ===\n",
      "\n",
      "Parameter: model.layers.0.self_attn.q_proj.weight\n",
      "Shape: torch.Size([1536, 1536])\n",
      "First few values:\n",
      "tensor([[-0.0300,  0.0226,  0.0251,  0.0065,  0.0058],\n",
      "        [-0.0177, -0.0050,  0.0713,  0.0150,  0.0315]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import torch.nn as nn\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "\n",
    "def inspect_layer(name, module):\n",
    "    \"\"\"Helper function to inspect a single layer\"\"\"\n",
    "    print(f\"\\n--- Layer: {name} ---\")\n",
    "    print(f\"Type: {type(module)}\")\n",
    "\n",
    "    # Check if it's a standard linear layer\n",
    "    if isinstance(module, nn.Linear):\n",
    "        print(f\"  Weight shape: {module.weight.shape} (out_features, in_features)\")\n",
    "        if module.bias is not None:\n",
    "            print(f\"  Bias shape: {module.bias.shape}\")\n",
    "        print(f\"  First weight values (3x3):\\n{module.weight.data[:3, :3]}\")\n",
    "\n",
    "    # Check for common patterns in transformer layers\n",
    "    if \"q_proj\" in name:\n",
    "        print(\"  [This appears to be a query projection]\")\n",
    "    elif \"k_proj\" in name:\n",
    "        print(\"  [This appears to be a key projection]\")\n",
    "    elif \"v_proj\" in name:\n",
    "        print(\"  [This appears to be a value projection]\")\n",
    "    elif \"o_proj\" in name:\n",
    "        print(\"  [This appears to be an output projection]\")\n",
    "    elif \"gate_proj\" in name or \"up_proj\" in name or \"down_proj\" in name:\n",
    "        print(\"  [This appears to be a feed-forward layer component]\")\n",
    "\n",
    "\n",
    "# Iterate through all layers\n",
    "for name, module in model.named_modules():\n",
    "    # Skip very high-level modules to reduce output\n",
    "    if len(name.split(\".\")) > 6:  # Adjust this number as needed\n",
    "        continue\n",
    "\n",
    "    # Only inspect certain types of layers\n",
    "    if isinstance(module, nn.Linear) or \"proj\" in name or \"attention\" in name:\n",
    "        inspect_layer(name, module)\n",
    "\n",
    "# Additional inspection of the first layer's weights\n",
    "print(\"\\n=== Detailed First Layer Inspection ===\")\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layers.0\" in name and \"weight\" in name:\n",
    "        print(f\"\\nParameter: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        print(\n",
    "            f\"First few values:\\n{param.data[:2, :5] if len(param.shape) > 1 else param.data[:5]}\"\n",
    "        )\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f9e29",
   "metadata": {},
   "source": [
    "# LLAMA3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6249a5ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3-8B.\n401 Client Error. (Request ID: Root=1-683353fb-51039aed3df2f93708f1d9e0;d16a0d44-2fe3-471d-beec-565097c2ccd1)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B is restricted. You must have access to it and be authenticated to access it. Please log in.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/requests/models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mGatedRepoError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:403\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    402\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     resolved_file = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:860\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    859\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m860\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:967\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m    966\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1482\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1480\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[32m   1481\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1484\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1374\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1294\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[39m\n\u001b[32m   1293\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1303\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:278\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:302\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    301\u001b[39m response = get_session().request(method=method, url=url, **params)\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:423\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    420\u001b[39m     message = (\n\u001b[32m    421\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    422\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_message == \u001b[33m\"\u001b[39m\u001b[33mAccess to this resource is disabled.\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mGatedRepoError\u001b[39m: 401 Client Error. (Request ID: Root=1-683353fb-51039aed3df2f93708f1d9e0;d16a0d44-2fe3-471d-beec-565097c2ccd1)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoConfig\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m original_config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta-llama/Meta-Llama-3-8B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(original_config)  \u001b[38;5;66;03m# Compare hidden_size, layers, etc.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1017\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1014\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1015\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1018\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1019\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:574\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    573\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    576\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:633\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    629\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    632\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    648\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:421\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    419\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[32m    420\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    422\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure to have access to it at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    423\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    424\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    427\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a local folder and is not a valid model identifier \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    428\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlisted on \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    429\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    430\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`token=<your_token>`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    431\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3-8B.\n401 Client Error. (Request ID: Root=1-683353fb-51039aed3df2f93708f1d9e0;d16a0d44-2fe3-471d-beec-565097c2ccd1)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B is restricted. You must have access to it and be authenticated to access it. Please log in."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "original_config = AutoConfig.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "print(original_config)  # Compare hidden_size, layers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233a5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2Config {\n",
      "  \"_name_or_path\": \"Qwen/Qwen1.5-1.8B\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151643,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5504,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "original_config = AutoConfig.from_pretrained(\"meta-llama/Meta-Llama-3-70B\")\n",
    "print(original_config)  # Compare hidden_size, layers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75561121",
   "metadata": {},
   "source": [
    "# DeepSeek V3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c899877c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Loading deepseek-ai/deepseek-v3 requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdeepseek-ai/deepseek-v3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(config)  \u001b[38;5;66;03m# Compare hidden_size, layers, etc.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1020\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1018\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1019\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n\u001b[32m-> \u001b[39m\u001b[32m1020\u001b[39m trust_remote_code = \u001b[43mresolve_trust_remote_code\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_local_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_remote_code\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[32m   1025\u001b[39m     class_ref = config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:678\u001b[39m, in \u001b[36mresolve_trust_remote_code\u001b[39m\u001b[34m(trust_remote_code, model_name, has_local_code, has_remote_code)\u001b[39m\n\u001b[32m    675\u001b[39m         _raise_timeout_error(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_local_code \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    679\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires you to execute the configuration file in that\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    680\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m repo on your local machine. Make sure you have read the code there to avoid malicious use, then\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m set the option `trust_remote_code=True` to remove this error.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trust_remote_code\n",
      "\u001b[31mValueError\u001b[39m: Loading deepseek-ai/deepseek-v3 requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error."
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"deepseek-ai/deepseek-v3\")\n",
    "print(config)  # Compare hidden_size, layers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e40f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "\n",
    "# Load models\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "summary(model, input_size=(1, 128), dtypes=[torch.int64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3fe33",
   "metadata": {},
   "source": [
    "# Inspect Layer Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4341fa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Inspecting: model.layers.0.self_attn.k_proj.pt\n",
      "==================================================\n",
      "[Type] <class 'dict'>\n",
      "\n",
      "[Quantized Weight Structure]\n",
      "Keys: ['qweight', 'qzeros', 'scales', 'bias']\n",
      "\n",
      "[ERROR] Failed to inspect /home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.self_attn.k_proj.pt: 'weight'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def inspect_quantized_file(file_path: Path, sample_size: int = 5):\n",
    "    \"\"\"\n",
    "    Inspects a quantized model file (.pt) and prints key information.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the .pt file\n",
    "        sample_size: Number of elements to display for sampling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        data = torch.load(file_path)\n",
    "        print(f\"\\n{'='*50}\\nInspecting: {file_path.name}\\n{'='*50}\")\n",
    "\n",
    "        # Basic info\n",
    "        print(f\"[Type] {type(data)}\")\n",
    "\n",
    "        if isinstance(data, torch.Tensor):\n",
    "            # Handle raw tensor case\n",
    "            print(\"\\n[Raw Tensor]\")\n",
    "            print(f\"Shape: {data.shape}\")\n",
    "            print(f\"dtype: {data.dtype}\")\n",
    "            print(f\"Device: {data.device}\")\n",
    "\n",
    "            # Statistics\n",
    "            if data.dtype in (torch.float16, torch.float32, torch.bfloat16):\n",
    "                data_float = data.float()\n",
    "                print(f\"\\n[Statistics]\")\n",
    "                print(f\"Min: {data_float.min().item():.4f}\")\n",
    "                print(f\"Max: {data_float.max().item():.4f}\")\n",
    "                print(f\"Mean: {data_float.mean().item():.4f}\")\n",
    "                print(f\"Std: {data_float.std().item():.4f}\")\n",
    "\n",
    "            # Sample values\n",
    "            print(f\"\\n[Sample Values (first {sample_size} elements)]\")\n",
    "            print(data.flatten()[:sample_size].tolist())\n",
    "\n",
    "            # Plot histogram if reasonable size\n",
    "            if data.numel() < 1e6:  # Don't plot for huge tensors\n",
    "                plt.figure(figsize=(10, 4))\n",
    "                plt.hist(data.float().cpu().numpy().flatten(), bins=50)\n",
    "                plt.title(f\"Value Distribution - {file_path.name}\")\n",
    "                plt.xlabel(\"Value\")\n",
    "                plt.ylabel(\"Frequency\")\n",
    "                plt.show()\n",
    "\n",
    "        elif isinstance(data, dict):\n",
    "            # Handle quantized weight dictionary\n",
    "            print(\"\\n[Quantized Weight Structure]\")\n",
    "            print(\"Keys:\", list(data.keys()))\n",
    "\n",
    "            # Required fields\n",
    "            qweight = data[\"weight\"]\n",
    "            print(f\"\\n[Weight Tensor]\")\n",
    "            print(f\"Shape: {qweight.shape}\")\n",
    "            print(f\"dtype: {qweight.dtype}\")\n",
    "            print(f\"Device: {qweight.device}\")\n",
    "\n",
    "            # Sample values\n",
    "            print(f\"\\n[Sample Weight Values (first {sample_size} elements)]\")\n",
    "            print(qweight.flatten()[:sample_size].tolist())\n",
    "\n",
    "            # Check for quantization parameters\n",
    "            if \"scales\" in data:\n",
    "                scales = data[\"scales\"]\n",
    "                print(f\"\\n[Scales]\")\n",
    "                print(f\"Shape: {scales.shape}\")\n",
    "                print(f\"Min: {scales.min().item():.4f}\")\n",
    "                print(f\"Max: {scales.max().item():.4f}\")\n",
    "                print(f\"Sample: {scales.flatten()[:sample_size].tolist()}\")\n",
    "\n",
    "            if \"zeros\" in data:\n",
    "                zeros = data[\"zeros\"]\n",
    "                print(f\"\\n[Zeros]\")\n",
    "                print(f\"Shape: {zeros.shape}\")\n",
    "                print(f\"Sample: {zeros.flatten()[:sample_size].tolist()}\")\n",
    "\n",
    "            if \"bias\" in data:\n",
    "                bias = data[\"bias\"]\n",
    "                print(f\"\\n[Bias]\")\n",
    "                print(f\"Shape: {bias.shape}\")\n",
    "                print(f\"Sample: {bias.flatten()[:sample_size].tolist()}\")\n",
    "\n",
    "            # Special handling for packed 4-bit weights\n",
    "            if qweight.dtype == torch.int32:\n",
    "                print(\"\\n[4-bit Packed Weights]\")\n",
    "                packed_val = qweight[0, 0].item()\n",
    "                unpacked = [(packed_val >> (4 * i)) & 0xF for i in range(8)]\n",
    "                print(f\"First packed int32: {packed_val} → Unpacked 4-bit: {unpacked}\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\n[Unknown data format]\")\n",
    "            print(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR] Failed to inspect {file_path}: {str(e)}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Configure these paths\n",
    "    base_dir = Path(\"/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\")\n",
    "    target_file = \"model.layers.0.self_attn.k_proj.pt\"  # Or use *.pt to process all\n",
    "\n",
    "    # Single file inspection\n",
    "    inspect_quantized_file(base_dir / target_file)\n",
    "\n",
    "    # Uncomment to process all .pt files in directory\n",
    "    # for pt_file in base_dir.glob(\"*.pt\"):\n",
    "    #     inspect_quantized_file(pt_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61ec2550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files: [PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.self_attn.v_proj.pt')]\n",
      "\n",
      "Contents of /home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.self_attn.q_proj.pt:\n",
      "----------------------------------------\n",
      "Dictionary contents:\n",
      "\n",
      "qweight:\n",
      "Shape: torch.Size([1536, 192])\n",
      "Dtype: torch.int32\n",
      "First few rows:\n",
      "tensor([[        0,         0,   1048576,         0,       256],\n",
      "        [        0,         0,         0,         0,         0],\n",
      "        [        0,         0,         0,         0,         0],\n",
      "        [        0,         0,         0,         0,         0],\n",
      "        [        0,         0,         0,         0, -16777216]],\n",
      "       dtype=torch.int32)\n",
      "\n",
      "qzeros:\n",
      "Shape: torch.Size([12, 192])\n",
      "Dtype: torch.int32\n",
      "First few rows:\n",
      "tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]], dtype=torch.int32)\n",
      "\n",
      "scales:\n",
      "Shape: torch.Size([12, 1536])\n",
      "Dtype: torch.float16\n",
      "First few rows:\n",
      "tensor([[0.2451, 0.2471, 0.2393, 0.2441, 0.2539],\n",
      "        [0.2422, 0.2539, 0.2451, 0.2422, 0.2422],\n",
      "        [0.3086, 0.3125, 0.3223, 0.3086, 0.3223],\n",
      "        [1.2344, 1.3359, 1.3203, 1.3984, 1.4609],\n",
      "        [1.0859, 1.2578, 1.3672, 1.1641, 1.2500]], dtype=torch.float16)\n",
      "\n",
      "bias:\n",
      "Shape: torch.Size([1536])\n",
      "Dtype: torch.float16\n",
      "First few values:\n",
      "tensor([ 0.2910, -0.2041,  0.7578, -0.3535, -0.1108], dtype=torch.float16,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path(\"/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\")\n",
    "print(\"Available files:\", list(base_dir.glob(\"*\")))\n",
    "\n",
    "layer_file = \"model.layers.0.self_attn.q_proj.pt\"  # Change as needed\n",
    "target_file = base_dir / layer_file\n",
    "data = torch.load(target_file)\n",
    "\n",
    "print(f\"\\nContents of {target_file}:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if isinstance(data, torch.Tensor):\n",
    "    print(f\"Tensor shape: {data.shape}\")\n",
    "    print(f\"Tensor dtype: {data.dtype}\")\n",
    "    print(\"\\nValues:\")\n",
    "    print(data)\n",
    "elif isinstance(data, dict):\n",
    "    print(\"Dictionary contents:\")\n",
    "    for key, value in data.items():\n",
    "        print(f\"\\n{key}:\")\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"Shape: {value.shape}\")\n",
    "            print(f\"Dtype: {value.dtype}\")\n",
    "            if value.numel() <= 10:  # Print full tensor if small\n",
    "                print(\"Values:\")\n",
    "                print(value)\n",
    "            else:\n",
    "                print(\n",
    "                    \"First few values:\" if len(value.shape) == 1 else \"First few rows:\"\n",
    "                )\n",
    "                print(value[:5] if len(value.shape) == 1 else value[:5, :5])\n",
    "        else:\n",
    "            print(value)\n",
    "else:\n",
    "    print(\"Unknown data type:\")\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba852846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contents of model.layers.0.self_attn.q_proj.pt:\n",
      "  qweight    → shape: (1536, 192), dtype: torch.int32\n",
      "  qzeros     → shape: (12, 192), dtype: torch.int32\n",
      "  scales     → shape: (12, 1536), dtype: torch.float16\n",
      "  bias       → shape: (1536,), dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the file\n",
    "base_dir = Path(\"/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\")\n",
    "layer_file = \"model.layers.0.self_attn.q_proj.pt\"\n",
    "target_file = base_dir / layer_file\n",
    "\n",
    "# Load the file\n",
    "data = torch.load(target_file, map_location=\"cpu\")\n",
    "\n",
    "print(f\"\\nContents of {layer_file}:\")\n",
    "\n",
    "if isinstance(data, dict):\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"  {key:<10} → shape: {tuple(value.shape)}, dtype: {value.dtype}\")\n",
    "        else:\n",
    "            print(f\"  {key:<10} → type: {type(value).__name__}\")\n",
    "else:\n",
    "    print(\"File content is not a dict.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ea438b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing model.layers.0.self_attn.q_proj.pt\n",
      "--------------------------------------------------\n",
      "Group size: 128\n",
      "Scales range: 0.1963 - 3.5938\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 128, 1536]' is invalid for input of size 18432",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m base_dir = Path(\u001b[33m\"\u001b[39m\u001b[33m/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m layer_file = \u001b[33m\"\u001b[39m\u001b[33mmodel.layers.0.self_attn.q_proj.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43manalyze_quantization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36manalyze_quantization\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScales range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscales.min().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscales.max().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Properly expand dimensions for broadcasting\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m scales = \u001b[43mscales\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscales\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [groups, group_size, out_features]\u001b[39;00m\n\u001b[32m     30\u001b[39m scales = scales.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# [groups, out_features, group_size]\u001b[39;00m\n\u001b[32m     31\u001b[39m scales = scales.reshape(-\u001b[32m1\u001b[39m, scales.shape[-\u001b[32m1\u001b[39m])  \u001b[38;5;66;03m# [groups*out_features, group_size]\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: shape '[-1, 128, 1536]' is invalid for input of size 18432"
     ]
    }
   ],
   "source": [
    "# check_quantization_efficiency.py\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def analyze_quantization(file_path):\n",
    "    data = torch.load(file_path)\n",
    "\n",
    "    if not isinstance(data, dict):\n",
    "        print(\"Error: Expected quantized layer dictionary\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nAnalyzing {file_path.name}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Extract parameters\n",
    "    qweight = data[\"qweight\"]  # shape: [in_features, out_features//8]\n",
    "    scales = data[\"scales\"]  # shape: [in_features//group_size, out_features]\n",
    "    qzeros = data[\"qzeros\"]  # shape: [in_features//group_size, out_features//8]\n",
    "\n",
    "    group_size = qweight.shape[0] // scales.shape[0]\n",
    "    print(f\"Group size: {group_size}\")\n",
    "    print(f\"Scales range: {scales.min().item():.4f} - {scales.max().item():.4f}\")\n",
    "\n",
    "    # Properly expand dimensions for broadcasting\n",
    "    scales = scales.view(\n",
    "        -1, group_size, scales.shape[-1]\n",
    "    )  # [groups, group_size, out_features]\n",
    "    scales = scales.transpose(1, 2)  # [groups, out_features, group_size]\n",
    "    scales = scales.reshape(-1, scales.shape[-1])  # [groups*out_features, group_size]\n",
    "\n",
    "    qzeros = qzeros.view(-1, 1, qzeros.shape[-1])  # [groups, 1, out_features//8]\n",
    "    qzeros = qzeros.expand(-1, group_size, -1)  # [groups, group_size, out_features//8]\n",
    "    qzeros = qzeros.reshape(-1, qzeros.shape[-1])  # [in_features, out_features//8]\n",
    "\n",
    "    # Dequantize sample weights\n",
    "    sample_qweight = qweight[:group_size]  # First group only for demo\n",
    "    sample_qzeros = qzeros[:group_size]\n",
    "    sample_scales = scales[:group_size]\n",
    "\n",
    "    dequant_weight = (sample_qweight - sample_qzeros) * sample_scales\n",
    "    print(\n",
    "        f\"Sample dequantized range: {dequant_weight.min().item():.4f} - {dequant_weight.max().item():.4f}\"\n",
    "    )\n",
    "\n",
    "    # Check 4-bit utilization\n",
    "    quantized_values = qweight.unique(sorted=True)\n",
    "    print(f\"Unique 4-bit values: {len(quantized_values)}/16\")\n",
    "    print(\n",
    "        f\"Value range: {quantized_values.min().item()} to {quantized_values.max().item()}\"\n",
    "    )\n",
    "\n",
    "    # Plot first group's weights\n",
    "    plt.hist(qweight[:group_size].cpu().flatten().numpy(), bins=16)\n",
    "    plt.title(\"4-bit Weight Values (First Group)\")\n",
    "    plt.xlabel(\"Quantized Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = Path(\"/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\")\n",
    "    layer_file = \"model.layers.0.self_attn.q_proj.pt\"\n",
    "    analyze_quantization(base_dir / layer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8c0a8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing model.layers.0.self_attn.q_proj.pt\n",
      "--------------------------------------------------\n",
      "Group size: 1536\n",
      "Scales range: 0.1963 - 3.5938\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1536) must match the size of tensor b (12) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     49\u001b[39m base_dir = Path(\u001b[33m\"\u001b[39m\u001b[33m/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m layer_file = \u001b[33m\"\u001b[39m\u001b[33mmodel.layers.0.self_attn.q_proj.pt\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Change as needed\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43manalyze_quantization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36manalyze_quantization\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScales range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscales.min().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscales.max().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Simulate dequantization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m dequant_weight = (\u001b[43mqweight\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mqzeros\u001b[49m) * scales\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     29\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDequantized weight range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdequant_weight.min().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdequant_weight.max().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Check 4-bit utilization\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (1536) must match the size of tensor b (12) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# check_quantization_efficiency.py\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def analyze_quantization(file_path):\n",
    "    data = torch.load(file_path)\n",
    "\n",
    "    if not isinstance(data, dict):\n",
    "        print(\"Error: Expected quantized layer dictionary (qweight, scales, qzeros)\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nAnalyzing {file_path.name}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Extract quantization parameters\n",
    "    qweight = data[\"qweight\"]\n",
    "    scales = data[\"scales\"]\n",
    "    qzeros = data[\"qzeros\"]\n",
    "    group_size = scales.shape[0] * (qweight.shape[0] // scales.shape[0])\n",
    "\n",
    "    print(f\"Group size: {group_size}\")\n",
    "    print(f\"Scales range: {scales.min().item():.4f} - {scales.max().item():.4f}\")\n",
    "\n",
    "    # Simulate dequantization\n",
    "    dequant_weight = (qweight - qzeros) * scales\n",
    "    print(\n",
    "        f\"Dequantized weight range: {dequant_weight.min().item():.4f} - {dequant_weight.max().item():.4f}\"\n",
    "    )\n",
    "\n",
    "    # Check 4-bit utilization\n",
    "    quantized_values = qweight.unique(sorted=True)\n",
    "    print(f\"Unique 4-bit values used: {len(quantized_values)}/16 possible\")\n",
    "    print(\n",
    "        f\"Value range: {quantized_values.min().item()} to {quantized_values.max().item()}\"\n",
    "    )\n",
    "\n",
    "    # Plot value distribution\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(qweight.cpu().flatten().numpy(), bins=50)\n",
    "    plt.title(f\"4-bit Weight Distribution\\n{file_path.name}\")\n",
    "    plt.xlabel(\"Quantized Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = Path(\"/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\")\n",
    "    layer_file = \"model.layers.0.self_attn.q_proj.pt\"  # Change as needed\n",
    "    analyze_quantization(base_dir / layer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c40d0023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - ✅ Logging configured successfully (console + file + resource.log)\n",
      "INFO - ✅ LOGGER DEBUG LEVEL IS ACTIVE\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import logging_config\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"✅ LOGGER DEBUG LEVEL IS ACTIVE\")\n",
    "logger.debug(\"✅ This debug message should appear if config is correct\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
