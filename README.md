<pre>
my_llm_tool/
â”œâ”€â”€ my_llm_tool/
    â”œâ”€â”€ api.py
    â”œâ”€â”€ task_manager.py
    â”œâ”€â”€ model_loader.py
    â”œâ”€â”€ batch_manager.py
</pre>

<pre>'''
my_llm_tool/
â”œâ”€â”€ my_llm_tool/
    â”œâ”€â”€ api.py
    â”œâ”€â”€ task_manager.py
    â”œâ”€â”€ model_loader.py
    â”œâ”€â”€ batch_manager.py
'''</pre>

## ðŸ”§ Installing AutoAWQ (for quantized model inference)

`autoawq` **must be installed manually** to avoid dependency resolution errors.

### Step 1: Ensure torch is already installed (from requirements.txt)

```bash
pip install -r requirements.txt --index-url https://download.pytorch.org/whl/cu121
