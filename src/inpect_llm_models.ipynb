{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2065fa2e",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ceec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import HTML\n",
    "from IPython.display import display\n",
    "from pprint import pformat\n",
    "\n",
    "\n",
    "def show_scrollable(content, height=\"300px\"):\n",
    "    \"\"\"\n",
    "    Show scrollable box in Jupyter with preserved indentation and dark theme.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(content, str):\n",
    "        content = pformat(content)\n",
    "\n",
    "    html = f\"\"\"\n",
    "    <div style=\"\n",
    "        height: {height};\n",
    "        overflow: auto;\n",
    "        background-color: black;\n",
    "        color: white;\n",
    "        border: 1px solid #444;\n",
    "        padding: 10px;\n",
    "        font-family: monospace;\n",
    "        white-space: pre;  /* <‚Äî THIS PRESERVES INDENTATION */\n",
    "    \">\n",
    "        {content}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f07a5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "\n",
    "def natural_key(text):\n",
    "    # Breaks text into chunks of digits and non-digits: \"layers.10\" ‚Üí [\"layers.\", 10]\n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r\"(\\d+)\", text)]\n",
    "\n",
    "\n",
    "def inspect_safetensors(path: str | Path, max_preview: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Return a readable, naturally sorted summary of a .safetensors file as a string.\n",
    "\n",
    "    Args:\n",
    "        path (str | Path): Path to the .safetensors file.\n",
    "        max_preview (int): Max number of values to preview for small tensors.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted summary string.\n",
    "    \"\"\"\n",
    "    path = Path(path).expanduser()\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "    state_dict = load_file(path)\n",
    "    sorted_items = sorted(state_dict.items(), key=lambda x: natural_key(x[0]))\n",
    "\n",
    "    lines = [\n",
    "        f\"üîç Inspecting {path.name} ‚Äî {len(sorted_items)} tensors found:\",\n",
    "        \"\",  # adds a single blank line after title\n",
    "    ]\n",
    "\n",
    "    for name, tensor in sorted_items:\n",
    "        lines.append(f\"- {name}: shape={tuple(tensor.shape)}, dtype={tensor.dtype}\")\n",
    "        if tensor.ndim <= 2 and tensor.numel() < 100:\n",
    "            preview = tensor.flatten()[:max_preview].tolist()\n",
    "            lines.append(f\"   preview: {preview}\")\n",
    "\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf712f8",
   "metadata": {},
   "source": [
    "# Inspecting Full Qwen2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a14d9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06bec89f791e4d359a8f72bd0890bf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like Qwen/Qwen2.5-72B is not the path to a directory containing a file named model-00003-of-00037.safetensors.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLocalEntryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:403\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    402\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     resolved_file = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:860\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    859\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m860\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:967\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m    966\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1476\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_files_only:\n\u001b[32m-> \u001b[39m\u001b[32m1476\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[32m   1477\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot find the requested files in the disk cache and outgoing traffic has been disabled. To enable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1478\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m hf.co look-ups and downloads online, set \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlocal_files_only\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to False.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1479\u001b[39m     )\n\u001b[32m   1480\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[32m   1481\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n",
      "\u001b[31mLocalEntryNotFoundError\u001b[39m: Cannot find the requested files in the disk cache and outgoing traffic has been disabled. To enable hf.co look-ups and downloads online, set 'local_files_only' to False.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mQwen/Qwen2.5-72B\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Loads architecture only, no weights\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Print layer names\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m model.named_parameters():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    563\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    568\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    570\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3973\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   3970\u001b[39m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[32m   3971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[32m   3972\u001b[39m     \u001b[38;5;66;03m# resolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3973\u001b[39m     resolved_archive_file, sharded_metadata = \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3989\u001b[39m     is_safetensors_available()\n\u001b[32m   3990\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m   3991\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file.endswith(\u001b[33m\"\u001b[39m\u001b[33m.safetensors\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   3992\u001b[39m ):\n\u001b[32m   3993\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:1098\u001b[39m, in \u001b[36mget_checkpoint_shard_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc=\u001b[33m\"\u001b[39m\u001b[33mDownloading shards\u001b[39m\u001b[33m\"\u001b[39m, disable=\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[32m   1096\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1097\u001b[39m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1098\u001b[39m         cached_filename = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m            \u001b[49m\u001b[43mshard_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[32m   1113\u001b[39m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:446\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    440\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    441\u001b[39m         resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    442\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries\n\u001b[32m    443\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors\n\u001b[32m    444\u001b[39m     ):\n\u001b[32m    445\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    447\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWe couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt connect to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to load this file, couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find it in the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    448\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m cached files and it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not the path to a directory containing a file named\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    449\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    451\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries:\n",
      "\u001b[31mOSError\u001b[39m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like Qwen/Qwen2.5-72B is not the path to a directory containing a file named model-00003-of-00037.safetensors.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-72B\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=\"meta\",  # Loads architecture only, no weights\n",
    "    local_files_only=True,\n",
    ")\n",
    "\n",
    "# Print layer names\n",
    "for name, _ in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc70e6",
   "metadata": {},
   "source": [
    "# Inspecting DS R1 Qwen Model - FULL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f31124c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2Config {\n",
      "  \"_name_or_path\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151643,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_mrope\": false,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "print(config)  # Full architecture details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dae52d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "Qwen2ForCausalLM                                   [1, 2, 128, 128]          --\n",
       "‚îú‚îÄQwen2Model: 1-1                                  [1, 2, 128, 128]          --\n",
       "‚îÇ    ‚îî‚îÄEmbedding: 2-1                              [1, 128, 1536]            233,373,696\n",
       "‚îÇ    ‚îî‚îÄQwen2RotaryEmbedding: 2-2                   [1, 128, 128]             --\n",
       "‚îÇ    ‚îî‚îÄModuleList: 2-3                             --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-1                 [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-2                 [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-3                 [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-4                 [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-5                 [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-6                 [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-7                 [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-8                 [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-9                 [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-10                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-11                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-12                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-13                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-14                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-15                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-16                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-17                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-18                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-19                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-20                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-21                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-22                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-23                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-24                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-25                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-26                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-27                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄQwen2DecoderLayer: 3-28                [1, 128, 1536]            46,797,824\n",
       "‚îÇ    ‚îî‚îÄQwen2RMSNorm: 2-4                           [1, 128, 1536]            1,536\n",
       "‚îú‚îÄLinear: 1-2                                      [1, 128, 151936]          233,373,696\n",
       "====================================================================================================\n",
       "Total params: 1,777,088,000\n",
       "Trainable params: 1,777,088,000\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.78\n",
       "====================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 907.41\n",
       "Params size (MB): 7108.35\n",
       "Estimated Total Size (MB): 8015.76\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "\n",
    "# Load models\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "summary(model, input_size=(1, 128), dtypes=[torch.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    # if \"layers\" in name and \"proj\" in name:\n",
    "    print(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d538ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2Config {\n",
      "  \"_name_or_path\": \"Qwen/Qwen1.5-1.8B\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151643,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5504,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "original_config = AutoConfig.from_pretrained(\"Qwen/Qwen1.5-1.8B\")\n",
    "print(original_config)  # Compare hidden_size, layers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9d445",
   "metadata": {},
   "source": [
    "## Inspect Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10a44c",
   "metadata": {},
   "source": [
    "### Peak Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f18e3646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Layer: model.layers.0.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0300,  0.0226,  0.0251],\n",
      "        [-0.0177, -0.0050,  0.0713],\n",
      "        [-0.0033, -0.0170,  0.0043]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.0.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0645,  0.0148, -0.1377],\n",
      "        [ 0.0254, -0.0625,  0.0957],\n",
      "        [ 0.0068, -0.0386, -0.0035]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.0.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0123, -0.0309,  0.0085],\n",
      "        [ 0.0025, -0.0030,  0.0259],\n",
      "        [ 0.0214,  0.0449, -0.0035]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.0.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0015,  0.0013, -0.0114],\n",
      "        [-0.0214,  0.0020,  0.0044],\n",
      "        [ 0.0430,  0.0229, -0.0354]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.0.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0266,  0.0369, -0.0342],\n",
      "        [-0.0210, -0.0135, -0.0405],\n",
      "        [ 0.0566, -0.0588,  0.0315]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.0.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0603, -0.0179,  0.0378],\n",
      "        [ 0.0104,  0.0085,  0.0270],\n",
      "        [-0.0035,  0.0195,  0.0361]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.0.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0064, -0.0107,  0.0212],\n",
      "        [ 0.0330, -0.0011,  0.0017],\n",
      "        [-0.0187,  0.0300,  0.0574]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.0.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.1.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0005,  0.0057, -0.0159],\n",
      "        [-0.0295,  0.0113, -0.0129],\n",
      "        [ 0.0532, -0.0128,  0.0243]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.1.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0084, -0.0461,  0.0123],\n",
      "        [ 0.0371,  0.0181,  0.0071],\n",
      "        [-0.0149,  0.0830,  0.0215]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.1.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0232, -0.0292, -0.0019],\n",
      "        [-0.0031,  0.0065, -0.0422],\n",
      "        [-0.0444, -0.0132, -0.0148]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.1.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0146,  0.0160,  0.0330],\n",
      "        [-0.0148, -0.0791,  0.0255],\n",
      "        [ 0.0060,  0.0364,  0.0513]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.1.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0162,  0.0233, -0.0415],\n",
      "        [ 0.0015,  0.0139, -0.0022],\n",
      "        [ 0.0991,  0.0510, -0.0162]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.1.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0283, -0.0063,  0.0708],\n",
      "        [ 0.0063,  0.0037,  0.0126],\n",
      "        [-0.0437, -0.0128, -0.0049]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.1.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0063,  0.0026, -0.0933],\n",
      "        [-0.0332, -0.0021, -0.0320],\n",
      "        [ 0.0269,  0.0066, -0.0050]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.1.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.2.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0072,  0.0032,  0.0640],\n",
      "        [-0.0139, -0.0393, -0.0135],\n",
      "        [-0.0107, -0.0649, -0.0908]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.2.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 1.7944e-02,  5.6458e-03,  3.2471e-02],\n",
      "        [-1.4954e-03,  3.5889e-02,  4.7302e-03],\n",
      "        [ 1.7212e-02,  3.5400e-02, -6.7711e-05]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.2.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0143, -0.0591, -0.0874],\n",
      "        [-0.0023,  0.0114,  0.0099],\n",
      "        [-0.0055, -0.0214, -0.0037]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.2.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0022, -0.0664, -0.0364],\n",
      "        [ 0.0201, -0.0128,  0.0381],\n",
      "        [-0.0036,  0.0569, -0.0403]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.2.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0278,  0.0457, -0.0388],\n",
      "        [ 0.0430, -0.0204,  0.0117],\n",
      "        [ 0.0540, -0.0310, -0.0576]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.2.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0554,  0.0233,  0.0515],\n",
      "        [ 0.0025, -0.0588, -0.0334],\n",
      "        [-0.0991,  0.0393, -0.0264]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.2.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0211,  0.0188,  0.0552],\n",
      "        [ 0.0250, -0.0569, -0.0177],\n",
      "        [ 0.0127,  0.0097,  0.0430]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.2.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.3.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0190, -0.0003,  0.0381],\n",
      "        [ 0.0022,  0.0099,  0.0649],\n",
      "        [-0.0041,  0.0549,  0.0654]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.3.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0247, -0.0074, -0.0118],\n",
      "        [ 0.0037,  0.0227,  0.0172],\n",
      "        [-0.0236, -0.0096, -0.0322]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.3.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0413,  0.0388, -0.0229],\n",
      "        [ 0.0742, -0.0649, -0.0265],\n",
      "        [ 0.0649,  0.0645,  0.0138]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.3.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0106, -0.0126,  0.0265],\n",
      "        [ 0.0236, -0.0261, -0.0649],\n",
      "        [ 0.0026,  0.0356, -0.0459]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.3.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0508,  0.0459, -0.0532],\n",
      "        [-0.0018, -0.0126,  0.1011],\n",
      "        [ 0.0262,  0.0184,  0.0522]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.3.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0437, -0.0442,  0.0100],\n",
      "        [ 0.0466,  0.0469,  0.0493],\n",
      "        [ 0.0840, -0.0459, -0.0388]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.3.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-3.7842e-02,  5.2979e-02, -5.4932e-02],\n",
      "        [-1.8188e-02, -3.2959e-02, -2.4292e-02],\n",
      "        [-5.3467e-02, -6.4453e-02,  2.7061e-05]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.3.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.4.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0369, -0.0036,  0.0339],\n",
      "        [-0.0212,  0.0226, -0.0137],\n",
      "        [ 0.0135, -0.0175, -0.0454]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.4.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0205, -0.0278,  0.0129],\n",
      "        [ 0.0339,  0.0194,  0.0160],\n",
      "        [ 0.0041,  0.0107,  0.0298]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.4.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0171, -0.0364,  0.0073],\n",
      "        [ 0.0027,  0.1328, -0.0376],\n",
      "        [ 0.0144,  0.0544, -0.0168]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.4.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0320, -0.0134,  0.0160],\n",
      "        [-0.0613,  0.0522, -0.0110],\n",
      "        [-0.0522,  0.1245, -0.0410]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.4.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0879, -0.0022, -0.0498],\n",
      "        [ 0.0056,  0.0518, -0.0234],\n",
      "        [-0.0579, -0.0325, -0.0354]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.4.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0234,  0.0615,  0.0189],\n",
      "        [ 0.0116, -0.0275,  0.0236],\n",
      "        [-0.0071,  0.0062, -0.0104]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.4.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0192,  0.0020,  0.0322],\n",
      "        [-0.0079,  0.0302,  0.0410],\n",
      "        [ 0.0009,  0.0231, -0.0054]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.4.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.5.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-7.1049e-05,  5.8289e-03,  2.5513e-02],\n",
      "        [-6.1340e-03, -3.6865e-02, -1.1658e-02],\n",
      "        [-3.1738e-03,  1.5259e-03,  3.8818e-02]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.5.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0040, -0.0233,  0.0422],\n",
      "        [ 0.0018,  0.0019,  0.0042],\n",
      "        [-0.0032, -0.0476,  0.0178]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.5.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0115,  0.0864, -0.0212],\n",
      "        [ 0.0084,  0.0164,  0.0630],\n",
      "        [-0.0151, -0.0542, -0.0432]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.5.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0334,  0.0038,  0.0211],\n",
      "        [-0.0160,  0.0364, -0.0371],\n",
      "        [-0.0027,  0.0981,  0.0840]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.5.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0327, -0.0123, -0.0688],\n",
      "        [-0.0403, -0.0476, -0.0654],\n",
      "        [ 0.0430,  0.0198, -0.0400]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.5.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0258, -0.0094, -0.0562],\n",
      "        [ 0.0518,  0.0347, -0.0245],\n",
      "        [ 0.0051, -0.0124,  0.0288]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.5.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0074, -0.0123,  0.0767],\n",
      "        [-0.0256,  0.0095, -0.0305],\n",
      "        [-0.0320,  0.0791,  0.0383]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.5.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.6.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0047, -0.0166,  0.0226],\n",
      "        [-0.0051,  0.0674,  0.0366],\n",
      "        [ 0.0149,  0.0068, -0.0208]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.6.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0109,  0.0035, -0.0364],\n",
      "        [ 0.0124, -0.0226,  0.0442],\n",
      "        [ 0.0110, -0.0110,  0.0081]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.6.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0120,  0.1226,  0.0571],\n",
      "        [ 0.0077, -0.0664,  0.0168],\n",
      "        [-0.0095,  0.0026,  0.0260]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.6.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0031, -0.0262,  0.0452],\n",
      "        [-0.0020,  0.0278, -0.0859],\n",
      "        [-0.0330, -0.0383,  0.0913]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.6.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0942,  0.0130,  0.0845],\n",
      "        [-0.0101, -0.0066,  0.0057],\n",
      "        [-0.0332, -0.0245, -0.0400]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.6.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0728, -0.0515,  0.0510],\n",
      "        [-0.0148, -0.0055,  0.0283],\n",
      "        [-0.0052, -0.0192,  0.0091]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.6.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0223,  0.0011, -0.0106],\n",
      "        [-0.0488, -0.0291,  0.0018],\n",
      "        [ 0.0608, -0.0349, -0.0376]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.6.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.7.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0054, -0.0256, -0.0029],\n",
      "        [ 0.0138, -0.0547,  0.0171],\n",
      "        [ 0.0074,  0.0154, -0.0109]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.7.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0256,  0.0243, -0.0089],\n",
      "        [ 0.0505,  0.0038, -0.0037],\n",
      "        [-0.0068, -0.0057, -0.0278]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.7.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0479,  0.0850,  0.0139],\n",
      "        [ 0.0732, -0.0034,  0.0122],\n",
      "        [ 0.0034, -0.0366,  0.0352]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.7.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0801, -0.0461, -0.0430],\n",
      "        [-0.1104,  0.0413,  0.0669],\n",
      "        [-0.0330,  0.0281, -0.0630]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.7.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0302, -0.0293,  0.0240],\n",
      "        [ 0.0123,  0.0334, -0.0559],\n",
      "        [-0.0280, -0.0659, -0.0142]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.7.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0099, -0.0023,  0.0067],\n",
      "        [ 0.0464, -0.0400,  0.0034],\n",
      "        [ 0.0007,  0.0099,  0.0020]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.7.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0148, -0.0344, -0.0103],\n",
      "        [ 0.0107, -0.0728,  0.0277],\n",
      "        [ 0.0058,  0.0029,  0.0254]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.7.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.8.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0640,  0.0820,  0.0747],\n",
      "        [-0.0408, -0.0047, -0.1084],\n",
      "        [ 0.0596, -0.0737, -0.0254]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.8.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0161, -0.0239,  0.0040],\n",
      "        [-0.0129, -0.0211, -0.0098],\n",
      "        [-0.0110,  0.0030,  0.0035]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.8.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0015, -0.0505,  0.0061],\n",
      "        [-0.0003,  0.0240, -0.0835],\n",
      "        [-0.0002,  0.0225, -0.0120]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.8.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0232, -0.0179,  0.0315],\n",
      "        [ 0.0131,  0.0042,  0.0776],\n",
      "        [-0.1118, -0.0140, -0.0464]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.8.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0564,  0.0227,  0.0625],\n",
      "        [-0.0388,  0.0206, -0.0320],\n",
      "        [-0.0036,  0.0184,  0.0014]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.8.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0371, -0.0835,  0.0605],\n",
      "        [ 0.0146,  0.0359, -0.0015],\n",
      "        [-0.0437, -0.0031,  0.0356]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.8.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0635, -0.0479,  0.0201],\n",
      "        [-0.0284,  0.0630, -0.0510],\n",
      "        [ 0.0130, -0.0825,  0.0381]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.8.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.9.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0039,  0.0864, -0.0078],\n",
      "        [-0.0280,  0.0547, -0.0104],\n",
      "        [-0.0031, -0.0059,  0.0515]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.9.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0248, -0.0210, -0.0045],\n",
      "        [-0.0344, -0.0061,  0.0028],\n",
      "        [ 0.0161, -0.0229,  0.0107]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.9.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-2.2583e-02, -5.3711e-02,  1.3428e-02],\n",
      "        [ 6.4697e-03, -4.6387e-03,  1.7762e-05],\n",
      "        [-6.4087e-03,  5.2002e-02, -1.7090e-02]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.9.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0304, -0.0381,  0.0226],\n",
      "        [ 0.0933,  0.0483, -0.0625],\n",
      "        [-0.0344,  0.0217, -0.0025]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.9.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0057, -0.0112,  0.0228],\n",
      "        [-0.0065,  0.0123, -0.0356],\n",
      "        [ 0.0294,  0.0261,  0.0161]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.9.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0291, -0.0537,  0.0425],\n",
      "        [ 0.0029,  0.0476, -0.0250],\n",
      "        [ 0.0059, -0.0347,  0.0025]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.9.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0221,  0.0181, -0.0449],\n",
      "        [-0.0008,  0.0199, -0.0294],\n",
      "        [-0.0359, -0.0137, -0.1021]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.9.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.10.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0049, -0.0034, -0.0193],\n",
      "        [ 0.0221, -0.0059, -0.0106],\n",
      "        [-0.0063,  0.0330, -0.0184]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.10.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0264, -0.0040,  0.0071],\n",
      "        [ 0.0074, -0.0123, -0.0117],\n",
      "        [-0.0150, -0.0149,  0.0153]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.10.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0087,  0.0840,  0.0271],\n",
      "        [ 0.0469, -0.0025, -0.0164],\n",
      "        [-0.0058, -0.0254, -0.0142]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.10.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0315, -0.0023,  0.0011],\n",
      "        [-0.0422,  0.0038, -0.0033],\n",
      "        [-0.0583, -0.0103, -0.0581]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.10.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0349,  0.0635,  0.0153],\n",
      "        [ 0.0547, -0.0554, -0.0635],\n",
      "        [ 0.0317, -0.0240, -0.0135]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.10.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0491, -0.0219, -0.0332],\n",
      "        [-0.0208,  0.0547, -0.0369],\n",
      "        [-0.0040,  0.0110,  0.0239]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.10.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0004, -0.0322, -0.0112],\n",
      "        [-0.0742,  0.0145,  0.0415],\n",
      "        [ 0.0237, -0.0165,  0.0282]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.10.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.11.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0286, -0.0160,  0.0161],\n",
      "        [ 0.0164,  0.0236, -0.0165],\n",
      "        [-0.0047,  0.0054,  0.0060]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.11.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0210, -0.0204,  0.0081],\n",
      "        [-0.0057, -0.0050, -0.0047],\n",
      "        [ 0.0022, -0.0166,  0.0045]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.11.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0068, -0.0037,  0.0104],\n",
      "        [ 0.0012, -0.0270, -0.0260],\n",
      "        [-0.0586,  0.0366, -0.0156]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.11.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0070, -0.0143, -0.0099],\n",
      "        [ 0.0136,  0.0308,  0.0811],\n",
      "        [ 0.0703, -0.0021,  0.0654]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.11.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0527, -0.0359,  0.0413],\n",
      "        [-0.0625, -0.0096,  0.0098],\n",
      "        [-0.0415, -0.0154,  0.0140]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.11.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0152,  0.0874,  0.0369],\n",
      "        [-0.0420, -0.0117, -0.0334],\n",
      "        [-0.0107, -0.0005,  0.0486]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.11.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0091, -0.0315, -0.0160],\n",
      "        [ 0.0635, -0.0015,  0.0425],\n",
      "        [-0.0398, -0.0447,  0.0079]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.11.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.12.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0112,  0.0123,  0.0003],\n",
      "        [ 0.0068,  0.0466, -0.0034],\n",
      "        [-0.0176,  0.0244, -0.0310]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.12.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0033,  0.0065,  0.0032],\n",
      "        [-0.0029, -0.0092,  0.0253],\n",
      "        [-0.0102,  0.0131,  0.0211]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.12.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0027, -0.0187, -0.0170],\n",
      "        [-0.0006,  0.0114, -0.0361],\n",
      "        [-0.0011, -0.0488,  0.0415]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.12.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0009,  0.0026,  0.0713],\n",
      "        [-0.0654,  0.0156, -0.0063],\n",
      "        [ 0.0090,  0.0019, -0.0493]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.12.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0913,  0.0150,  0.0459],\n",
      "        [ 0.0439, -0.0162,  0.0312],\n",
      "        [-0.0177,  0.0613,  0.0352]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.12.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0211,  0.0085, -0.0210],\n",
      "        [-0.0015,  0.0270,  0.0330],\n",
      "        [ 0.0491,  0.0046, -0.0270]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.12.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0417,  0.0374, -0.0269],\n",
      "        [-0.0153, -0.0048,  0.0532],\n",
      "        [-0.0439, -0.0016, -0.0209]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.12.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.13.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0255,  0.0225, -0.0024],\n",
      "        [ 0.0261,  0.0019,  0.0011],\n",
      "        [ 0.0152,  0.0032,  0.0635]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.13.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0074,  0.0092,  0.0060],\n",
      "        [ 0.0198, -0.0114, -0.0166],\n",
      "        [-0.0012, -0.0019, -0.0096]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.13.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0205, -0.0186,  0.0139],\n",
      "        [-0.0275, -0.0228, -0.0513],\n",
      "        [-0.0052,  0.0275, -0.0095]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.13.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0052,  0.0146, -0.0034],\n",
      "        [ 0.0226, -0.0708, -0.0381],\n",
      "        [ 0.0110,  0.0991,  0.0645]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.13.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0415, -0.1235,  0.0732],\n",
      "        [-0.0574,  0.0786, -0.0126],\n",
      "        [-0.0291, -0.0552,  0.0254]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.13.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0104,  0.0510,  0.0068],\n",
      "        [-0.0515, -0.0430,  0.0216],\n",
      "        [-0.0422, -0.0297, -0.0049]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.13.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0330,  0.0234, -0.0208],\n",
      "        [ 0.0149, -0.0062, -0.0947],\n",
      "        [-0.0013,  0.0064, -0.0093]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.13.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.14.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0083,  0.0228,  0.0102],\n",
      "        [-0.0028,  0.0277,  0.0017],\n",
      "        [ 0.0150,  0.0036, -0.0028]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.14.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0320, -0.0084, -0.0015],\n",
      "        [-0.0001,  0.0058, -0.0036],\n",
      "        [-0.0141,  0.0012, -0.0005]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.14.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0080, -0.0098, -0.0107],\n",
      "        [ 0.0120, -0.0082,  0.0195],\n",
      "        [-0.0559,  0.0315, -0.0312]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.14.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0276, -0.0019,  0.0322],\n",
      "        [ 0.0237,  0.0112,  0.0245],\n",
      "        [ 0.0840, -0.0053, -0.0437]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.14.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0938,  0.0437,  0.0603],\n",
      "        [-0.0430,  0.0405, -0.0260],\n",
      "        [-0.0270, -0.0391,  0.0815]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.14.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0117,  0.0212, -0.0052],\n",
      "        [-0.0598, -0.0310, -0.0254],\n",
      "        [ 0.0265,  0.0566,  0.0459]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.14.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0020,  0.0132,  0.0327],\n",
      "        [-0.0294, -0.0327,  0.0874],\n",
      "        [-0.0374, -0.0337,  0.0245]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.14.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.15.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0405,  0.0215, -0.0347],\n",
      "        [ 0.0142, -0.0154,  0.0107],\n",
      "        [ 0.0188,  0.0708, -0.0052]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.15.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0311,  0.0432,  0.0082],\n",
      "        [-0.0679, -0.0115,  0.0102],\n",
      "        [-0.0182, -0.0060, -0.0175]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.15.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0161, -0.0183, -0.0540],\n",
      "        [-0.0231, -0.0261,  0.0206],\n",
      "        [ 0.0356, -0.0610,  0.0199]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.15.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0113, -0.0019, -0.0209],\n",
      "        [ 0.0204,  0.0356,  0.0435],\n",
      "        [-0.0898,  0.0400,  0.0243]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.15.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0337,  0.0374,  0.0162],\n",
      "        [-0.0364,  0.0518,  0.0310],\n",
      "        [-0.0064,  0.0444,  0.0752]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.15.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0151,  0.0045, -0.0032],\n",
      "        [-0.0359, -0.0386,  0.0400],\n",
      "        [-0.0376, -0.1035, -0.0004]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.15.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0021, -0.0099, -0.0723],\n",
      "        [ 0.0132, -0.0503, -0.0903],\n",
      "        [ 0.0325,  0.0576, -0.0415]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.15.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.16.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0292,  0.0189, -0.0071],\n",
      "        [ 0.0219,  0.0109, -0.0099],\n",
      "        [ 0.0310, -0.0225,  0.0181]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.16.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 9.5215e-03,  2.4719e-03,  9.5215e-03],\n",
      "        [-4.8584e-02, -1.1536e-02,  1.1902e-02],\n",
      "        [-1.3489e-02, -1.4832e-02, -1.1802e-05]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.16.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0014,  0.0208,  0.0122],\n",
      "        [ 0.0234, -0.0114,  0.0069],\n",
      "        [ 0.0889, -0.0211,  0.0253]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.16.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0223, -0.0334, -0.0068],\n",
      "        [ 0.0137, -0.0179, -0.0991],\n",
      "        [-0.0192, -0.0133,  0.0464]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.16.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0869,  0.0581,  0.0669],\n",
      "        [-0.0165,  0.0309,  0.0396],\n",
      "        [-0.0014, -0.0054,  0.0237]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.16.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0361, -0.0549, -0.0420],\n",
      "        [-0.0229,  0.0601, -0.0386],\n",
      "        [ 0.0422, -0.1025, -0.0747]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.16.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-2.8320e-02, -2.2583e-02, -2.8320e-02],\n",
      "        [-8.3496e-02, -3.7354e-02, -1.8555e-02],\n",
      "        [ 6.4850e-05,  2.5513e-02,  3.5889e-02]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.16.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.17.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0630,  0.0415,  0.0193],\n",
      "        [-0.0300,  0.0189,  0.0417],\n",
      "        [ 0.0302,  0.0161, -0.0422]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.17.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0194, -0.0024,  0.0028],\n",
      "        [-0.0057,  0.0172,  0.0190],\n",
      "        [-0.0068, -0.0177, -0.0108]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.17.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0002, -0.0300, -0.0216],\n",
      "        [-0.0036, -0.1191, -0.0283],\n",
      "        [ 0.0092, -0.1108, -0.0432]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.17.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0142,  0.0271, -0.0085],\n",
      "        [ 0.0535, -0.0688, -0.0253],\n",
      "        [-0.0493,  0.0248, -0.1270]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.17.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0344, -0.0069,  0.0175],\n",
      "        [ 0.0055,  0.0432,  0.0532],\n",
      "        [ 0.0233,  0.0085,  0.0151]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.17.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0356,  0.0391,  0.0688],\n",
      "        [-0.0115, -0.0562,  0.0242],\n",
      "        [-0.0277, -0.0280,  0.0405]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.17.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0040,  0.0159, -0.0004],\n",
      "        [ 0.0214,  0.0032,  0.0260],\n",
      "        [ 0.0105, -0.0654, -0.0165]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.17.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.18.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0630, -0.0317, -0.0084],\n",
      "        [-0.0542,  0.0129, -0.0309],\n",
      "        [ 0.0179,  0.0051,  0.0170]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.18.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0233, -0.0005,  0.0089],\n",
      "        [ 0.0281,  0.0054,  0.0074],\n",
      "        [ 0.0059, -0.0145, -0.0007]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.18.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0640,  0.0020,  0.0522],\n",
      "        [ 0.0923, -0.0247, -0.0688],\n",
      "        [-0.0713, -0.0083, -0.0081]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.18.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0229,  0.0014,  0.0150],\n",
      "        [ 0.0420, -0.0723,  0.0366],\n",
      "        [ 0.0996, -0.1436, -0.1533]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.18.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0020,  0.0398, -0.0391],\n",
      "        [-0.0150,  0.0432,  0.0118],\n",
      "        [ 0.0128,  0.0493, -0.0165]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.18.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-3.1006e-02,  9.9609e-02,  1.7700e-02],\n",
      "        [-6.3782e-03,  1.7822e-02,  2.2949e-02],\n",
      "        [ 1.9165e-02, -6.6895e-02,  7.2479e-05]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.18.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0177, -0.0344,  0.0025],\n",
      "        [ 0.0718, -0.0435, -0.0275],\n",
      "        [-0.0286,  0.0104, -0.0227]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.18.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.19.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0540,  0.0171,  0.0203],\n",
      "        [ 0.0400,  0.0089, -0.0135],\n",
      "        [-0.0030,  0.0322, -0.0044]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.19.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0081,  0.0136, -0.0064],\n",
      "        [-0.0003,  0.0019,  0.0002],\n",
      "        [ 0.0243,  0.0012,  0.0113]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.19.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0022,  0.0493, -0.0659],\n",
      "        [-0.0112, -0.0266, -0.0171],\n",
      "        [ 0.2910,  0.0388,  0.0244]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.19.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0248,  0.0447, -0.0410],\n",
      "        [-0.0033,  0.0139, -0.0879],\n",
      "        [-0.1719,  0.0781,  0.0444]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.19.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0466, -0.0092,  0.0483],\n",
      "        [-0.0378, -0.0298,  0.0518],\n",
      "        [ 0.0159,  0.0020,  0.2109]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.19.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0491, -0.0211, -0.0085],\n",
      "        [-0.0525, -0.0369,  0.0698],\n",
      "        [ 0.0097, -0.0154, -0.2734]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.19.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0608, -0.0067, -0.0288],\n",
      "        [ 0.0050, -0.0226,  0.0454],\n",
      "        [-0.0201,  0.0457, -0.0864]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.19.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.20.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0386,  0.0356,  0.0095],\n",
      "        [ 0.0146,  0.0493,  0.0349],\n",
      "        [-0.0588, -0.0479,  0.0220]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.20.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 3.1586e-03,  5.8289e-03,  4.3335e-03],\n",
      "        [ 6.1035e-05,  1.0742e-02, -2.4414e-03],\n",
      "        [-7.6904e-03,  1.8555e-02,  4.3945e-03]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.20.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0820, -0.0229, -0.0306],\n",
      "        [ 0.0203,  0.0845,  0.0098],\n",
      "        [-0.0014, -0.0640,  0.0133]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.20.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-1.8799e-02,  4.2969e-02, -4.9072e-02],\n",
      "        [-9.7168e-02,  7.1716e-03,  1.2695e-01],\n",
      "        [-1.0204e-04, -1.2695e-01, -1.8677e-02]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.20.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0327, -0.0177, -0.0527],\n",
      "        [ 0.0732, -0.0067, -0.0308],\n",
      "        [-0.0031,  0.0776, -0.0530]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.20.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0190,  0.0020,  0.0618],\n",
      "        [-0.0752,  0.0051,  0.0161],\n",
      "        [-0.0194,  0.0320, -0.0742]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.20.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0125,  0.0013,  0.0058],\n",
      "        [-0.0752,  0.0148,  0.0147],\n",
      "        [-0.0255,  0.0104,  0.0498]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.20.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.21.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0469, -0.0393,  0.0120],\n",
      "        [ 0.0311,  0.0435,  0.0037],\n",
      "        [ 0.0137,  0.0079, -0.0003]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.21.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0018, -0.0083, -0.0154],\n",
      "        [-0.0131, -0.0459,  0.0009],\n",
      "        [-0.0117,  0.0277, -0.0107]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.21.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.1157,  0.0281,  0.0135],\n",
      "        [-0.0035, -0.0356, -0.0435],\n",
      "        [ 0.0273,  0.0143, -0.0175]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.21.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0008,  0.0339, -0.0254],\n",
      "        [ 0.0312,  0.1201,  0.0820],\n",
      "        [ 0.0136,  0.0317, -0.0457]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.21.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0022,  0.0232,  0.0393],\n",
      "        [-0.0486, -0.0342,  0.0261],\n",
      "        [-0.0259, -0.0002,  0.0242]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.21.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0244, -0.0181,  0.0938],\n",
      "        [ 0.0322, -0.0067, -0.0295],\n",
      "        [ 0.0105, -0.0544,  0.0067]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.21.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0330, -0.0029, -0.0366],\n",
      "        [-0.0054,  0.0405, -0.0535],\n",
      "        [ 0.0347, -0.0245,  0.0053]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.21.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.22.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0059,  0.0261, -0.0225],\n",
      "        [ 0.0161,  0.0183, -0.0160],\n",
      "        [ 0.0251, -0.0118, -0.0369]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.22.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0038, -0.0025, -0.0020],\n",
      "        [-0.0060,  0.0288,  0.0077],\n",
      "        [-0.0067,  0.0093,  0.0110]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.22.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0297, -0.0420, -0.0072],\n",
      "        [-0.0110, -0.0115,  0.0236],\n",
      "        [-0.0249,  0.1953, -0.0220]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.22.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0459, -0.0051,  0.0102],\n",
      "        [-0.0154, -0.0405,  0.0942],\n",
      "        [ 0.0261,  0.0483, -0.0640]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.22.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0928, -0.0527, -0.0010],\n",
      "        [ 0.0087,  0.0117, -0.0408],\n",
      "        [ 0.0033,  0.0277, -0.0166]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.22.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0684,  0.0120, -0.0205],\n",
      "        [-0.0339, -0.0610, -0.0128],\n",
      "        [ 0.0003,  0.0210, -0.0081]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.22.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0173,  0.0221,  0.0014],\n",
      "        [-0.0383, -0.0165, -0.0415],\n",
      "        [-0.0303,  0.0210,  0.0022]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.22.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.23.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0237,  0.0242, -0.0134],\n",
      "        [ 0.0134, -0.0225, -0.0129],\n",
      "        [-0.0019,  0.0079,  0.0347]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.23.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0065, -0.0024,  0.0150],\n",
      "        [-0.0074, -0.0188,  0.0137],\n",
      "        [ 0.0051, -0.0039, -0.0040]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.23.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.1328,  0.0150, -0.0060],\n",
      "        [ 0.0159,  0.0120, -0.0015],\n",
      "        [-0.1396, -0.0005,  0.0009]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.23.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0265, -0.0320, -0.0118],\n",
      "        [ 0.0752, -0.0381,  0.0601],\n",
      "        [-0.0071, -0.0176,  0.0039]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.23.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0413, -0.0183,  0.0479],\n",
      "        [ 0.0074,  0.0356,  0.0718],\n",
      "        [-0.0396,  0.0291,  0.0040]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.23.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0354,  0.0615,  0.0237],\n",
      "        [ 0.0505, -0.0549, -0.0251],\n",
      "        [-0.0449, -0.0157, -0.0737]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.23.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0417, -0.0330,  0.0101],\n",
      "        [ 0.0525, -0.0430,  0.0107],\n",
      "        [ 0.0474,  0.0091, -0.0275]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.23.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.24.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[0.0024, 0.0109, 0.0066],\n",
      "        [0.0034, 0.0079, 0.0187],\n",
      "        [0.0107, 0.0067, 0.0284]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.24.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0063, -0.0447, -0.0042],\n",
      "        [-0.0079,  0.0242,  0.0010],\n",
      "        [-0.0027,  0.0255,  0.0232]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.24.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0267,  0.0747,  0.0239],\n",
      "        [ 0.0201,  0.0496, -0.0256],\n",
      "        [-0.0001, -0.0016, -0.0059]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.24.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0175, -0.0094,  0.0354],\n",
      "        [ 0.0698, -0.0025,  0.0530],\n",
      "        [-0.0496, -0.0295, -0.0879]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.24.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0019, -0.0231,  0.0664],\n",
      "        [ 0.0347,  0.0649,  0.0347],\n",
      "        [-0.0262, -0.0292,  0.0270]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.24.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0017, -0.0244, -0.0170],\n",
      "        [ 0.0613, -0.0320, -0.0645],\n",
      "        [ 0.0820,  0.0747,  0.0339]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.24.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0291,  0.0227, -0.0146],\n",
      "        [ 0.0693,  0.0166, -0.0098],\n",
      "        [ 0.0069, -0.0028, -0.0041]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.24.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.25.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0042, -0.0001,  0.0151],\n",
      "        [ 0.0069, -0.0466, -0.0339],\n",
      "        [-0.0117,  0.0493, -0.0250]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.25.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0048, -0.0010, -0.0095],\n",
      "        [-0.0029,  0.0292,  0.0062],\n",
      "        [-0.0043,  0.0034, -0.0238]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.25.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.1455, -0.1172,  0.0216],\n",
      "        [-0.0234, -0.0320, -0.0120],\n",
      "        [-0.1089,  0.0002,  0.0645]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.25.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0327,  0.0476,  0.0308],\n",
      "        [-0.0630, -0.0510,  0.0238],\n",
      "        [ 0.0112,  0.0537, -0.0713]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.25.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0083,  0.0192,  0.0091],\n",
      "        [ 0.0752,  0.0051, -0.0031],\n",
      "        [ 0.0659,  0.0593, -0.0261]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.25.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0236, -0.0194, -0.0315],\n",
      "        [-0.0366,  0.0308,  0.0479],\n",
      "        [ 0.0981,  0.0049, -0.0349]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.25.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0522,  0.0457, -0.0588],\n",
      "        [-0.0125, -0.0220, -0.0500],\n",
      "        [-0.0359, -0.0337,  0.0189]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.25.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.26.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0178, -0.0400, -0.0179],\n",
      "        [ 0.0150,  0.0199,  0.0091],\n",
      "        [ 0.0062, -0.0269,  0.0087]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.26.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0116, -0.0172,  0.0052],\n",
      "        [ 0.0025, -0.0034,  0.0072],\n",
      "        [ 0.0060,  0.0160, -0.0177]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.26.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0728,  0.0009, -0.0123],\n",
      "        [ 0.0347, -0.0170, -0.0009],\n",
      "        [ 0.1494, -0.0049,  0.0189]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.26.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0238,  0.0075,  0.0415],\n",
      "        [ 0.1021, -0.0535,  0.0325],\n",
      "        [ 0.0078,  0.0469, -0.0156]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.26.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0089,  0.0112, -0.0435],\n",
      "        [ 0.0791,  0.0089,  0.0486],\n",
      "        [-0.0026,  0.0620,  0.0079]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.26.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0461, -0.0195,  0.0806],\n",
      "        [-0.0544,  0.0115,  0.0122],\n",
      "        [ 0.0271,  0.0160, -0.0332]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.26.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0703, -0.0933,  0.0145],\n",
      "        [-0.0032, -0.0398,  0.0576],\n",
      "        [ 0.0210, -0.0145, -0.0309]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.26.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: model.layers.27.self_attn.q_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([1536])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0032,  0.0564, -0.0186],\n",
      "        [ 0.0011,  0.0236, -0.0047],\n",
      "        [-0.0090,  0.0094,  0.0018]])\n",
      "  [This appears to be a query projection]\n",
      "\n",
      "--- Layer: model.layers.27.self_attn.k_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0022, -0.0342,  0.0020],\n",
      "        [-0.0115, -0.0083, -0.0125],\n",
      "        [ 0.0086, -0.0041, -0.0225]])\n",
      "  [This appears to be a key projection]\n",
      "\n",
      "--- Layer: model.layers.27.self_attn.v_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([256, 1536]) (out_features, in_features)\n",
      "  Bias shape: torch.Size([256])\n",
      "  First weight values (3x3):\n",
      "tensor([[ 8.1055e-02, -7.7637e-02,  1.2665e-03],\n",
      "        [-9.2773e-02, -1.3733e-02, -2.2217e-02],\n",
      "        [ 2.0874e-02, -8.3008e-03,  1.3888e-05]])\n",
      "  [This appears to be a value projection]\n",
      "\n",
      "--- Layer: model.layers.27.self_attn.o_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0150,  0.0214, -0.0442],\n",
      "        [-0.0398, -0.0359,  0.0044],\n",
      "        [-0.0620,  0.0620,  0.0757]])\n",
      "  [This appears to be an output projection]\n",
      "\n",
      "--- Layer: model.layers.27.mlp.gate_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.1118,  0.0111, -0.0679],\n",
      "        [-0.0400, -0.0168,  0.0040],\n",
      "        [ 0.0640,  0.0067, -0.0479]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.27.mlp.up_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([8960, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0260,  0.0830,  0.0854],\n",
      "        [-0.0090, -0.0069, -0.0060],\n",
      "        [ 0.0376, -0.0270,  0.0786]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.27.mlp.down_proj ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([1536, 8960]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[-0.0447,  0.0231,  0.0383],\n",
      "        [ 0.0300, -0.0322, -0.0359],\n",
      "        [-0.0244, -0.0444, -0.0605]])\n",
      "  [This appears to be a feed-forward layer component]\n",
      "\n",
      "--- Layer: model.layers.27.post_attention_layernorm ---\n",
      "Type: <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "\n",
      "--- Layer: lm_head ---\n",
      "Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "  Weight shape: torch.Size([151936, 1536]) (out_features, in_features)\n",
      "  First weight values (3x3):\n",
      "tensor([[ 0.0776,  0.0293, -0.0143],\n",
      "        [ 0.0518, -0.0444,  0.0284],\n",
      "        [ 0.0269, -0.0486, -0.0099]])\n",
      "\n",
      "=== Detailed First Layer Inspection ===\n",
      "\n",
      "Parameter: model.layers.0.self_attn.q_proj.weight\n",
      "Shape: torch.Size([1536, 1536])\n",
      "First few values:\n",
      "tensor([[-0.0300,  0.0226,  0.0251,  0.0065,  0.0058],\n",
      "        [-0.0177, -0.0050,  0.0713,  0.0150,  0.0315]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import torch.nn as nn\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "\n",
    "def inspect_layer(name, module):\n",
    "    \"\"\"Helper function to inspect a single layer\"\"\"\n",
    "    print(f\"\\n--- Layer: {name} ---\")\n",
    "    print(f\"Type: {type(module)}\")\n",
    "\n",
    "    # Check if it's a standard linear layer\n",
    "    if isinstance(module, nn.Linear):\n",
    "        print(f\"  Weight shape: {module.weight.shape} (out_features, in_features)\")\n",
    "        if module.bias is not None:\n",
    "            print(f\"  Bias shape: {module.bias.shape}\")\n",
    "        print(f\"  First weight values (3x3):\\n{module.weight.data[:3, :3]}\")\n",
    "\n",
    "    # Check for common patterns in transformer layers\n",
    "    if \"q_proj\" in name:\n",
    "        print(\"  [This appears to be a query projection]\")\n",
    "    elif \"k_proj\" in name:\n",
    "        print(\"  [This appears to be a key projection]\")\n",
    "    elif \"v_proj\" in name:\n",
    "        print(\"  [This appears to be a value projection]\")\n",
    "    elif \"o_proj\" in name:\n",
    "        print(\"  [This appears to be an output projection]\")\n",
    "    elif \"gate_proj\" in name or \"up_proj\" in name or \"down_proj\" in name:\n",
    "        print(\"  [This appears to be a feed-forward layer component]\")\n",
    "\n",
    "\n",
    "# Iterate through all layers\n",
    "for name, module in model.named_modules():\n",
    "    # Skip very high-level modules to reduce output\n",
    "    if len(name.split(\".\")) > 6:  # Adjust this number as needed\n",
    "        continue\n",
    "\n",
    "    # Only inspect certain types of layers\n",
    "    if isinstance(module, nn.Linear) or \"proj\" in name or \"attention\" in name:\n",
    "        inspect_layer(name, module)\n",
    "\n",
    "# Additional inspection of the first layer's weights\n",
    "print(\"\\n=== Detailed First Layer Inspection ===\")\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layers.0\" in name and \"weight\" in name:\n",
    "        print(f\"\\nParameter: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        print(\n",
    "            f\"First few values:\\n{param.data[:2, :5] if len(param.shape) > 1 else param.data[:5]}\"\n",
    "        )\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af059f",
   "metadata": {},
   "source": [
    "### Weight distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbeddbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>type</th>\n",
       "      <th>shape</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>zero_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model.layers.0.self_attn.q_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(1536, 1536)</td>\n",
       "      <td>-0.953125</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>1.750172e-05</td>\n",
       "      <td>0.053037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model.layers.0.self_attn.k_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(256, 1536)</td>\n",
       "      <td>-0.384766</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>-8.440000e-05</td>\n",
       "      <td>0.061757</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model.layers.0.self_attn.v_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(256, 1536)</td>\n",
       "      <td>-0.159180</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>-1.660858e-05</td>\n",
       "      <td>0.030817</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model.layers.0.self_attn.o_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(1536, 1536)</td>\n",
       "      <td>-0.597656</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>3.382745e-06</td>\n",
       "      <td>0.046337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model.layers.0.mlp.gate_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(8960, 1536)</td>\n",
       "      <td>-0.753906</td>\n",
       "      <td>0.660156</td>\n",
       "      <td>-4.833728e-07</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model.layers.0.mlp.up_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(8960, 1536)</td>\n",
       "      <td>-0.457031</td>\n",
       "      <td>0.419922</td>\n",
       "      <td>-5.622278e-06</td>\n",
       "      <td>0.034311</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model.layers.0.mlp.down_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(1536, 8960)</td>\n",
       "      <td>-0.550781</td>\n",
       "      <td>0.519531</td>\n",
       "      <td>1.262973e-05</td>\n",
       "      <td>0.036591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model.layers.1.self_attn.q_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(1536, 1536)</td>\n",
       "      <td>-0.386719</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>-1.325980e-05</td>\n",
       "      <td>0.040712</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model.layers.1.self_attn.k_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(256, 1536)</td>\n",
       "      <td>-0.341797</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>-3.723954e-05</td>\n",
       "      <td>0.053641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model.layers.1.self_attn.v_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(256, 1536)</td>\n",
       "      <td>-0.217773</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>3.042569e-05</td>\n",
       "      <td>0.031537</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>model.layers.1.self_attn.o_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(1536, 1536)</td>\n",
       "      <td>-0.746094</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>-4.657109e-05</td>\n",
       "      <td>0.048069</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>model.layers.1.mlp.gate_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(8960, 1536)</td>\n",
       "      <td>-0.531250</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>-1.391528e-04</td>\n",
       "      <td>0.041104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model.layers.1.mlp.up_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(8960, 1536)</td>\n",
       "      <td>-0.542969</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>-5.409225e-06</td>\n",
       "      <td>0.037177</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model.layers.1.mlp.down_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(1536, 8960)</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>-1.388098e-05</td>\n",
       "      <td>0.037183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>model.layers.2.self_attn.q_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(1536, 1536)</td>\n",
       "      <td>-0.589844</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>5.410079e-05</td>\n",
       "      <td>0.040616</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>model.layers.2.self_attn.k_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(256, 1536)</td>\n",
       "      <td>-0.400391</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>-5.674783e-05</td>\n",
       "      <td>0.047785</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>model.layers.2.self_attn.v_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(256, 1536)</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>0.191406</td>\n",
       "      <td>2.652831e-05</td>\n",
       "      <td>0.031185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>model.layers.2.self_attn.o_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(1536, 1536)</td>\n",
       "      <td>-0.570312</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>-1.735032e-05</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>model.layers.2.mlp.gate_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(8960, 1536)</td>\n",
       "      <td>-0.539062</td>\n",
       "      <td>0.398438</td>\n",
       "      <td>-3.038841e-04</td>\n",
       "      <td>0.042733</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>model.layers.2.mlp.up_proj</td>\n",
       "      <td>Linear</td>\n",
       "      <td>(8960, 1536)</td>\n",
       "      <td>-0.490234</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>1.314533e-05</td>\n",
       "      <td>0.035866</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              layer    type         shape       min       max  \\\n",
       "0   model.layers.0.self_attn.q_proj  Linear  (1536, 1536) -0.953125  0.960938   \n",
       "1   model.layers.0.self_attn.k_proj  Linear   (256, 1536) -0.384766  0.394531   \n",
       "2   model.layers.0.self_attn.v_proj  Linear   (256, 1536) -0.159180  0.197266   \n",
       "3   model.layers.0.self_attn.o_proj  Linear  (1536, 1536) -0.597656  0.605469   \n",
       "4      model.layers.0.mlp.gate_proj  Linear  (8960, 1536) -0.753906  0.660156   \n",
       "5        model.layers.0.mlp.up_proj  Linear  (8960, 1536) -0.457031  0.419922   \n",
       "6      model.layers.0.mlp.down_proj  Linear  (1536, 8960) -0.550781  0.519531   \n",
       "7   model.layers.1.self_attn.q_proj  Linear  (1536, 1536) -0.386719  0.394531   \n",
       "8   model.layers.1.self_attn.k_proj  Linear   (256, 1536) -0.341797  0.406250   \n",
       "9   model.layers.1.self_attn.v_proj  Linear   (256, 1536) -0.217773  0.189453   \n",
       "10  model.layers.1.self_attn.o_proj  Linear  (1536, 1536) -0.746094  0.539062   \n",
       "11     model.layers.1.mlp.gate_proj  Linear  (8960, 1536) -0.531250  0.402344   \n",
       "12       model.layers.1.mlp.up_proj  Linear  (8960, 1536) -0.542969  0.453125   \n",
       "13     model.layers.1.mlp.down_proj  Linear  (1536, 8960) -0.625000  0.640625   \n",
       "14  model.layers.2.self_attn.q_proj  Linear  (1536, 1536) -0.589844  0.535156   \n",
       "15  model.layers.2.self_attn.k_proj  Linear   (256, 1536) -0.400391  0.341797   \n",
       "16  model.layers.2.self_attn.v_proj  Linear   (256, 1536) -0.179688  0.191406   \n",
       "17  model.layers.2.self_attn.o_proj  Linear  (1536, 1536) -0.570312  0.503906   \n",
       "18     model.layers.2.mlp.gate_proj  Linear  (8960, 1536) -0.539062  0.398438   \n",
       "19       model.layers.2.mlp.up_proj  Linear  (8960, 1536) -0.490234  0.558594   \n",
       "\n",
       "            mean       std  zero_ratio  \n",
       "0   1.750172e-05  0.053037         0.0  \n",
       "1  -8.440000e-05  0.061757         0.0  \n",
       "2  -1.660858e-05  0.030817         0.0  \n",
       "3   3.382745e-06  0.046337         0.0  \n",
       "4  -4.833728e-07  0.038473         0.0  \n",
       "5  -5.622278e-06  0.034311         0.0  \n",
       "6   1.262973e-05  0.036591         0.0  \n",
       "7  -1.325980e-05  0.040712         0.0  \n",
       "8  -3.723954e-05  0.053641         0.0  \n",
       "9   3.042569e-05  0.031537         0.0  \n",
       "10 -4.657109e-05  0.048069         0.0  \n",
       "11 -1.391528e-04  0.041104         0.0  \n",
       "12 -5.409225e-06  0.037177         0.0  \n",
       "13 -1.388098e-05  0.037183         0.0  \n",
       "14  5.410079e-05  0.040616         0.0  \n",
       "15 -5.674783e-05  0.047785         0.0  \n",
       "16  2.652831e-05  0.031185         0.0  \n",
       "17 -1.735032e-05  0.049860         0.0  \n",
       "18 -3.038841e-04  0.042733         0.0  \n",
       "19  1.314533e-05  0.035866         0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "\n",
    "def collect_layer_weight_stats(model):\n",
    "    \"\"\"\n",
    "    Collect weight statistics (min, max, mean, std, sparsity) for each Linear layer in the model.\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            weight = module.weight.data\n",
    "\n",
    "            stats.append(\n",
    "                {\n",
    "                    \"layer\": name,\n",
    "                    \"type\": \"Linear\",\n",
    "                    \"shape\": tuple(weight.shape),\n",
    "                    \"min\": weight.min().item(),\n",
    "                    \"max\": weight.max().item(),\n",
    "                    \"mean\": weight.mean().item(),\n",
    "                    \"std\": weight.std().item(),\n",
    "                    \"zero_ratio\": (weight == 0).float().mean().item(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(stats)\n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "df_stats = collect_layer_weight_stats(model)\n",
    "\n",
    "# Show top 20 layers with highest sparsity\n",
    "df_top_sparse = df_stats.sort_values(\"zero_ratio\", ascending=False).head(20)\n",
    "\n",
    "# Output results\n",
    "display(dataframe=df_stats)\n",
    "df_top_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12c96831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average zero ratio across groups: 91.43%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# Load original model\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# Choose a specific layer to inspect\n",
    "layer = model.model.layers[0].mlp.gate_proj\n",
    "weight = layer.weight.data  # shape: (8960, 1536)\n",
    "\n",
    "# Simulate group-wise scaling\n",
    "group_size = 128\n",
    "num_groups = weight.shape[0] // group_size\n",
    "qweight_sim = []\n",
    "zero_ratios = []\n",
    "\n",
    "for g in range(num_groups):\n",
    "    start = g * group_size\n",
    "    end = (g + 1) * group_size\n",
    "    w_slice = weight[start:end, :]\n",
    "\n",
    "    # Use 99th percentile as simulated scale\n",
    "    scale = torch.quantile(w_slice.abs(), 0.99)\n",
    "    scale = max(scale.item(), 1e-5)  # Avoid divide-by-zero\n",
    "\n",
    "    # Simulate quantization\n",
    "    scaled = w_slice / scale\n",
    "    rounded = torch.round(scaled)\n",
    "\n",
    "    # Simulate clamping to 4-bit range [0‚Äì15]\n",
    "    q = torch.clamp(rounded, 0, 15)\n",
    "\n",
    "    # Track zero ratio\n",
    "    zero_ratio = (q == 0).float().mean().item()\n",
    "    zero_ratios.append(zero_ratio)\n",
    "\n",
    "print(f\"Average zero ratio across groups: {sum(zero_ratios)/len(zero_ratios):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f9e29",
   "metadata": {},
   "source": [
    "# LLAMA3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6249a5ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3-8B.\n401 Client Error. (Request ID: Root=1-683353fb-51039aed3df2f93708f1d9e0;d16a0d44-2fe3-471d-beec-565097c2ccd1)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B is restricted. You must have access to it and be authenticated to access it. Please log in.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/requests/models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mGatedRepoError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:403\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    402\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     resolved_file = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:860\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    859\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m860\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:967\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m    966\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1482\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1480\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[32m   1481\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1484\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1374\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1294\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[39m\n\u001b[32m   1293\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1303\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:278\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:302\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    301\u001b[39m response = get_session().request(method=method, url=url, **params)\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:423\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    420\u001b[39m     message = (\n\u001b[32m    421\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    422\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_message == \u001b[33m\"\u001b[39m\u001b[33mAccess to this resource is disabled.\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mGatedRepoError\u001b[39m: 401 Client Error. (Request ID: Root=1-683353fb-51039aed3df2f93708f1d9e0;d16a0d44-2fe3-471d-beec-565097c2ccd1)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoConfig\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m original_config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta-llama/Meta-Llama-3-8B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(original_config)  \u001b[38;5;66;03m# Compare hidden_size, layers, etc.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1017\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1014\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1015\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1018\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1019\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:574\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    573\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    576\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:633\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    629\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    632\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    648\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:421\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    419\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[32m    420\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    422\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure to have access to it at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    423\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    424\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    427\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a local folder and is not a valid model identifier \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    428\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlisted on \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    429\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    430\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`token=<your_token>`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    431\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3-8B.\n401 Client Error. (Request ID: Root=1-683353fb-51039aed3df2f93708f1d9e0;d16a0d44-2fe3-471d-beec-565097c2ccd1)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B is restricted. You must have access to it and be authenticated to access it. Please log in."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "original_config = AutoConfig.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "print(original_config)  # Compare hidden_size, layers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233a5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2Config {\n",
      "  \"_name_or_path\": \"Qwen/Qwen1.5-1.8B\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151643,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5504,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "original_config = AutoConfig.from_pretrained(\"meta-llama/Meta-Llama-3-70B\")\n",
    "print(original_config)  # Compare hidden_size, layers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75561121",
   "metadata": {},
   "source": [
    "# DeepSeek V3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899877c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d7213f59664db999216cdfd9683fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_deepseek.py:   0%|          | 0.00/75.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/deepseek-v3:\n",
      "- modeling_deepseek.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown quantization type, got fp8 - supported types are: ['awq', 'bitsandbytes_4bit', 'bitsandbytes_8bit', 'gptq', 'aqlm', 'quanto', 'eetq', 'hqq', 'compressed-tensors', 'fbgemm_fp8', 'torchao', 'bitnet']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdeepseek-ai/deepseek-v3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# No memory/download used\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Required for DeepSeek\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Allow fetching config (tiny file)\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Print all layer names + shapes (fake tensors)\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model.named_parameters():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:559\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28mcls\u001b[39m.register(config.\u001b[34m__class__\u001b[39m, model_class, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    558\u001b[39m     model_class = add_generation_mixin_to_remote_model(model_class)\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    563\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3646\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   3644\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pre_quantized \u001b[38;5;129;01mor\u001b[39;00m quantization_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3645\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pre_quantized:\n\u001b[32m-> \u001b[39m\u001b[32m3646\u001b[39m         config.quantization_config = \u001b[43mAutoHfQuantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge_quantization_configs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3647\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\n\u001b[32m   3648\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3649\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3650\u001b[39m         config.quantization_config = quantization_config\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/quantizers/auto.py:173\u001b[39m, in \u001b[36mAutoHfQuantizer.merge_quantization_configs\u001b[39m\u001b[34m(cls, quantization_config, quantization_config_from_args)\u001b[39m\n\u001b[32m    170\u001b[39m     warning_msg = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(quantization_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     quantization_config = \u001b[43mAutoQuantizationConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    176\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(quantization_config, (GPTQConfig, AwqConfig, FbgemmFp8Config))\n\u001b[32m    177\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m quantization_config_from_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    178\u001b[39m ):\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# special case for GPTQ / AWQ / FbgemmFp8 config collision\u001b[39;00m\n\u001b[32m    180\u001b[39m     loading_attr_dict = quantization_config_from_args.get_loading_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deepseek_local_runner/.venv/lib/python3.12/site-packages/transformers/quantizers/auto.py:97\u001b[39m, in \u001b[36mAutoQuantizationConfig.from_dict\u001b[39m\u001b[34m(cls, quantization_config_dict)\u001b[39m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     93\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe model\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms quantization config from the arguments has no `quant_method` attribute. Make sure that the model has been correctly quantized\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     94\u001b[39m     )\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m quant_method \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m AUTO_QUANTIZATION_CONFIG_MAPPING.keys():\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     98\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown quantization type, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - supported types are:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     99\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(AUTO_QUANTIZER_MAPPING.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     )\n\u001b[32m    102\u001b[39m target_cls = AUTO_QUANTIZATION_CONFIG_MAPPING[quant_method]\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m target_cls.from_dict(quantization_config_dict)\n",
      "\u001b[31mValueError\u001b[39m: Unknown quantization type, got fp8 - supported types are: ['awq', 'bitsandbytes_4bit', 'bitsandbytes_8bit', 'gptq', 'aqlm', 'quanto', 'eetq', 'hqq', 'compressed-tensors', 'fbgemm_fp8', 'torchao', 'bitnet']"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"deepseek-ai/deepseek-v3\")\n",
    "print(config)\n",
    "\n",
    "# Infer layer names (DeepSeek follows LLaMA-style)\n",
    "num_layers = config.num_hidden_layers\n",
    "print(f\"Expected layers: model.layers.0...{num_layers-1}\")\n",
    "print(\"Each layer contains: self_attn.q_proj, mlp.gate_proj, etc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e40f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "\n",
    "# Load models\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "summary(model, input_size=(1, 128), dtypes=[torch.int64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3fe33",
   "metadata": {},
   "source": [
    "# Inspect Layer Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61ec2550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files: [PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.19.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.27.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.2.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.20.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.8.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.12.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.22.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.8.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.18.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.26.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.1.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.18.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.16.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.10.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.21.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.13.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.2.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.5.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.25.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.8.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.2.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.6.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.1.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.19.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.25.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.18.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.22.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.9.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.18.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.6.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.1.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.6.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.10.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.15.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.2.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.3.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.13.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.9.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.17.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.24.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.15.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.7.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.5.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.10.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.15.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.23.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.24.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.7.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.26.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.3.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.13.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.26.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.1.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.21.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.3.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.21.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.18.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.9.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.10.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.7.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.11.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.26.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.14.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.6.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.5.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.7.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.2.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.14.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.13.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.9.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.4.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.19.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.15.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.12.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.9.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.16.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.20.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.17.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.27.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.4.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.8.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.14.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.15.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.5.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.13.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.25.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.20.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.11.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.16.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.19.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.17.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.11.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.6.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.22.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.25.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.7.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.4.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.25.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.24.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.6.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.7.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.26.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.23.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.13.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.20.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.27.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.21.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.23.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.14.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.12.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.16.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.11.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.27.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.22.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.20.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.17.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.21.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.17.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.14.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.19.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.24.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.11.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.18.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.15.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.3.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.22.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.3.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.11.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.1.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.12.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.12.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.23.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.26.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.24.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.25.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.19.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.10.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.4.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.24.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.17.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.16.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.23.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.9.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.5.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.22.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.27.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.8.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.2.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.4.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.8.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.23.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.0.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.5.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.4.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.12.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.16.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.14.self_attn.q_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.1.self_attn.v_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.21.mlp.up_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.27.self_attn.k_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.10.mlp.down_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.3.mlp.gate_proj.pt'), PosixPath('/home/xzhang/models/deepseek-awq-scrooge/quantized_layers/model.layers.20.self_attn.k_proj.pt')]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path(\"/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\")\n",
    "print(\"Available files:\", list(base_dir.glob(\"*\")))\n",
    "\n",
    "layer_file = \"model.layers.0.self_attn.q_proj.pt\"  # Change as needed\n",
    "target_file = base_dir / layer_file\n",
    "data = torch.load(target_file)\n",
    "\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47044212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary contents:\n",
      "\n",
      "qweight:\n",
      "Shape: torch.Size([8960, 192])\n",
      "Dtype: torch.int32\n",
      "First few rows:\n",
      "tensor([[      -31,        -1,       -46,        -2,        -2],\n",
      "        [      -15,       -30,       -29,        -2,        -1],\n",
      "        [       -2,        -1,       -32,       -15,       -63],\n",
      "        [       -4,   1057297,        -1,    -11518,       -48],\n",
      "        [-62840528,        -1,      -254,        -1,        -2]],\n",
      "       dtype=torch.int32)\n",
      "\n",
      "qzeros:\n",
      "Shape: torch.Size([70, 192])\n",
      "Dtype: torch.int32\n",
      "First few rows:\n",
      "tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]], dtype=torch.int32)\n",
      "\n",
      "scales:\n",
      "Shape: torch.Size([70, 1536])\n",
      "Dtype: torch.float16\n",
      "First few rows:\n",
      "tensor([[0.0199, 0.0199, 0.0199, 0.0199, 0.0199],\n",
      "        [0.0575, 0.0575, 0.0575, 0.0575, 0.0575],\n",
      "        [0.0683, 0.0683, 0.0683, 0.0683, 0.0683],\n",
      "        [0.0374, 0.0374, 0.0374, 0.0374, 0.0374],\n",
      "        [0.0129, 0.0129, 0.0129, 0.0129, 0.0129]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "086d5cba",
   "metadata": {},
   "source": [
    "## All Files - Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7592aead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üì¶ File: model.layers.0.mlp.down_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(8960, 192), dtype=torch.int32\n",
      "qzeros: shape=(70, 192), dtype=torch.int32\n",
      "scales: shape=(70, 1536), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.0.mlp.gate_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.0.mlp.up_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.0.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.0.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.0.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.1.mlp.down_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(8960, 192), dtype=torch.int32\n",
      "qzeros: shape=(70, 192), dtype=torch.int32\n",
      "scales: shape=(70, 1536), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.1.mlp.gate_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.1.mlp.up_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.1.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.1.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.1.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.10.mlp.down_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(8960, 192), dtype=torch.int32\n",
      "qzeros: shape=(70, 192), dtype=torch.int32\n",
      "scales: shape=(70, 1536), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.10.mlp.gate_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.10.mlp.up_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.10.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.10.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.10.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.11.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.11.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.11.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.2.mlp.down_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(8960, 192), dtype=torch.int32\n",
      "qzeros: shape=(70, 192), dtype=torch.int32\n",
      "scales: shape=(70, 1536), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.2.mlp.gate_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.2.mlp.up_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.2.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.2.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.2.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.3.mlp.down_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(8960, 192), dtype=torch.int32\n",
      "qzeros: shape=(70, 192), dtype=torch.int32\n",
      "scales: shape=(70, 1536), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.3.mlp.gate_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.3.mlp.up_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.3.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.3.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.3.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.4.mlp.down_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(8960, 192), dtype=torch.int32\n",
      "qzeros: shape=(70, 192), dtype=torch.int32\n",
      "scales: shape=(70, 1536), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.4.mlp.gate_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.4.mlp.up_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.4.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.4.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.4.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.5.mlp.down_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(8960, 192), dtype=torch.int32\n",
      "qzeros: shape=(70, 192), dtype=torch.int32\n",
      "scales: shape=(70, 1536), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.5.mlp.gate_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.5.mlp.up_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.5.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.5.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.5.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.6.mlp.down_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(8960, 192), dtype=torch.int32\n",
      "qzeros: shape=(70, 192), dtype=torch.int32\n",
      "scales: shape=(70, 1536), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.6.mlp.gate_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.6.mlp.up_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.6.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.6.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.6.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.7.mlp.down_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(8960, 192), dtype=torch.int32\n",
      "qzeros: shape=(70, 192), dtype=torch.int32\n",
      "scales: shape=(70, 1536), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.7.mlp.gate_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.7.mlp.up_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.7.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.7.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.7.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.8.mlp.down_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(8960, 192), dtype=torch.int32\n",
      "qzeros: shape=(70, 192), dtype=torch.int32\n",
      "scales: shape=(70, 1536), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.8.mlp.gate_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.8.mlp.up_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.8.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.8.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.8.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.9.mlp.down_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(8960, 192), dtype=torch.int32\n",
      "qzeros: shape=(70, 192), dtype=torch.int32\n",
      "scales: shape=(70, 1536), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.9.mlp.gate_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.9.mlp.up_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "scales: shape=(12, 8960), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.9.self_attn.k_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.9.self_attn.q_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 192), dtype=torch.int32\n",
      "qzeros: shape=(12, 192), dtype=torch.int32\n",
      "scales: shape=(12, 1536), dtype=torch.float16\n",
      "bias: shape=(1536,), dtype=torch.float16\n",
      "================================================================================\n",
      "================================================================================\n",
      "üì¶ File: model.layers.9.self_attn.v_proj.pt\n",
      "--------------------------------------------------------------------------------\n",
      "qweight: shape=(1536, 32), dtype=torch.int32\n",
      "qzeros: shape=(12, 32), dtype=torch.int32\n",
      "scales: shape=(12, 256), dtype=torch.float16\n",
      "bias: shape=(256,), dtype=torch.float16\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from project_config import DEEPSEEK_R1_DISTILL_QUANT_MODEL_OUTPUT_DIR\n",
    "\n",
    "base_dir = DEEPSEEK_R1_DISTILL_QUANT_MODEL_OUTPUT_DIR / \"quantized_layers\"\n",
    "\n",
    "# Iterate over all .pt files under quantized_layers\n",
    "for pt_file in sorted(base_dir.glob(\"**/*.pt\")):\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üì¶ File: {pt_file.relative_to(base_dir)}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    try:\n",
    "        data = torch.load(pt_file, map_location=\"cpu\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load: {e}\")\n",
    "        continue\n",
    "\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        print(f\"Tensor shape: {data.shape}\")\n",
    "        print(f\"Tensor dtype: {data.dtype}\")\n",
    "\n",
    "    elif isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                print(f\"{key}: shape={tuple(value.shape)}, dtype={value.dtype}\")\n",
    "            else:\n",
    "                print(f\"{key}: non-tensor value (type={type(value).__name__})\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Unknown object type: {type(data)}\")\n",
    "\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a9401e",
   "metadata": {},
   "source": [
    "## Qweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1973cf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Inspecting 11 layer files in: /home/xzhang/models/deepseek-awq-scrooge/quantized_layers\n",
      "\n",
      "model.layers.0.mlp.down_proj.pt          | shape: (8960, 192)          | zeros: 0.80% | unique[:10]: [-2147483632, -2147483595, -2147478528, -2147477696, -2147471184, -2147463135, -2147351983, -2147342333, -2147286528, -2147270592] ‚úÖ\n",
      "\n",
      "model.layers.0.mlp.gate_proj.pt          | shape: (1536, 1120)         | zeros: 1.48% | unique[:10]: [-2147483632, -2147483136, -2147482605, -2147477706, -2147469259, -2147458810, -2147454684, -2147411712, -2147409151, -2147405529] ‚úÖ\n",
      "\n",
      "model.layers.0.mlp.up_proj.pt            | shape: (1536, 1120)         | zeros: 3.10% | unique[:10]: [-2143018463, -2130636768, -1877794043, -1861152494, -1861082576, -1860168944, -1859911150, -1859055340, -1844444879, -1843068415] ‚úÖ\n",
      "\n",
      "model.layers.0.self_attn.k_proj.pt       | shape: (1536, 32)           | zeros: 4.22% | unique[:10]: [-2147465929, -2147286224, -2146239273, -2145711647, -2140118910, -2132942554, -2130898540, -2130403142, -2130104181, -2113228400] ‚úÖ\n",
      "\n",
      "model.layers.0.self_attn.q_proj.pt       | shape: (1536, 192)          | zeros: 8.61% | unique[:10]: [-2147483638, -2147483616, -2147475454, -2147474905, -2147458956, -2145254901, -2144821040, -2143288576, -2142631052, -2140638624] ‚úÖ\n",
      "\n",
      "model.layers.0.self_attn.v_proj.pt       | shape: (1536, 32)           | zeros: 1.54% | unique[:10]: [-2145246039, -2141144991, -2111315297, -2105514998, -2097055951, -2090624476, -2080208636, -2076988576, -2063154648, -1997127085] ‚úÖ\n",
      "\n",
      "model.layers.1.mlp.gate_proj.pt          | shape: (1536, 1120)         | zeros: 0.32% | unique[:10]: [-2147470287, -2147449294, -2147446010, -2147340250, -2147319532, -2147269004, -2147076541, -2147065584, -2146360749, -2146102000] ‚úÖ\n",
      "\n",
      "model.layers.1.mlp.up_proj.pt            | shape: (1536, 1120)         | zeros: 0.10% | unique[:10]: [-2147462047, -2147450878, -2147417328, -2147413983, -2147352301, -2147284907, -2147273193, -2147264412, -2147253760, -2147250111] ‚úÖ\n",
      "\n",
      "model.layers.1.self_attn.k_proj.pt       | shape: (1536, 32)           | zeros: 2.51% | unique[:10]: [-2140121472, -2110644213, -2092609503, -2087714755, -2071252114, -2063400947, -2058302595, -2044706780, -1995226985, -1988075360] ‚úÖ\n",
      "\n",
      "model.layers.1.self_attn.q_proj.pt       | shape: (1536, 192)          | zeros: 2.47% | unique[:10]: [-2147483648, -2147465206, -2147460304, -2147250150, -2147200591, -2147161344, -2146542159, -2146366608, -2145845235, -2145613964] ‚úÖ\n",
      "\n",
      "model.layers.1.self_attn.v_proj.pt       | shape: (1536, 32)           | zeros: 1.66% | unique[:10]: [-2147073772, -2140076332, -2131398546, -2130644744, -2097119226, -2097046711, -2087503280, -2014684833, -1935668839, -1878848901] ‚úÖ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def inspect_qweights_in_dir(layer_dir: Path, zero_threshold: float = 0.9):\n",
    "    \"\"\"\n",
    "    Inspect qweight statistics for all saved quantized layer files in a directory.\n",
    "\n",
    "    Args:\n",
    "        layer_dir (Path): Directory containing *.pt quantized layer files.\n",
    "        zero_threshold (float): Warn if percentage of zeros in qweight exceeds this.\n",
    "    \"\"\"\n",
    "    layer_dir = Path(layer_dir).expanduser()\n",
    "    if not layer_dir.exists():\n",
    "        raise FileNotFoundError(f\"Directory not found: {layer_dir}\")\n",
    "\n",
    "    pt_files = sorted(layer_dir.glob(\"*.pt\"))\n",
    "    if not pt_files:\n",
    "        print(\"‚ùå No .pt layer files found in directory.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüîç Inspecting {len(pt_files)} layer files in: {layer_dir}\\n\")\n",
    "\n",
    "    for f in pt_files:\n",
    "        try:\n",
    "            state_dict = torch.load(f, map_location=\"cpu\")\n",
    "            qweight = state_dict.get(\"qweight\", None)\n",
    "\n",
    "            if qweight is None:\n",
    "                print(f\"‚ö†Ô∏è  {f.name}: Missing `qweight` key.\")\n",
    "                continue\n",
    "\n",
    "            zeros = (qweight == 0).sum().item()\n",
    "            total = qweight.numel()\n",
    "            zero_pct = zeros / total\n",
    "\n",
    "            unique_vals = torch.unique(qweight)\n",
    "            preview_vals = unique_vals.tolist()[:10]\n",
    "\n",
    "            flag = \"‚ö†Ô∏è HIGH ZERO RATIO!\" if zero_pct > zero_threshold else \"‚úÖ\"\n",
    "\n",
    "            # ‚úÖ FIX: Convert tuple to string before formatting\n",
    "            shape_str = str(tuple(qweight.shape))\n",
    "\n",
    "            print(\n",
    "                f\"{f.name:<40} | shape: {shape_str:<20} | \"\n",
    "                f\"zeros: {zero_pct:.2%} | unique[:10]: {preview_vals} {flag}\"\n",
    "            )\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {f.name}: Error loading or parsing file ‚Äî {str(e)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage ‚Äî adjust this path if needed\n",
    "    quantized_dir = Path(\"~/models/deepseek-awq-scrooge/quantized_layers\")\n",
    "    inspect_qweights_in_dir(quantized_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba852846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contents of model.layers.0.self_attn.q_proj.pt:\n",
      "  qweight    ‚Üí shape: (1536, 192), dtype: torch.int32\n",
      "  qzeros     ‚Üí shape: (12, 192), dtype: torch.int32\n",
      "  scales     ‚Üí shape: (12, 1536), dtype: torch.float16\n",
      "  bias       ‚Üí shape: (1536,), dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the file\n",
    "base_dir = Path(\"/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\")\n",
    "layer_file = \"model.layers.0.self_attn.q_proj.pt\"\n",
    "target_file = base_dir / layer_file\n",
    "\n",
    "# Load the file\n",
    "data = torch.load(target_file, map_location=\"cpu\")\n",
    "\n",
    "print(f\"\\nContents of {layer_file}:\")\n",
    "\n",
    "if isinstance(data, dict):\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"  {key:<10} ‚Üí shape: {tuple(value.shape)}, dtype: {value.dtype}\")\n",
    "        else:\n",
    "            print(f\"  {key:<10} ‚Üí type: {type(value).__name__}\")\n",
    "else:\n",
    "    print(\"File content is not a dict.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea438b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing model.layers.0.self_attn.q_proj.pt\n",
      "--------------------------------------------------\n",
      "Group size: 128\n",
      "Scales range: 0.0072 - 0.1002\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 128, 1536]' is invalid for input of size 18432",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m base_dir = Path(\u001b[33m\"\u001b[39m\u001b[33m/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m layer_file = \u001b[33m\"\u001b[39m\u001b[33mmodel.layers.0.self_attn.q_proj.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43manalyze_quantization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36manalyze_quantization\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScales range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscales.min().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscales.max().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Properly expand dimensions for broadcasting\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m scales = \u001b[43mscales\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscales\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [groups, group_size, out_features]\u001b[39;00m\n\u001b[32m     30\u001b[39m scales = scales.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# [groups, out_features, group_size]\u001b[39;00m\n\u001b[32m     31\u001b[39m scales = scales.reshape(-\u001b[32m1\u001b[39m, scales.shape[-\u001b[32m1\u001b[39m])  \u001b[38;5;66;03m# [groups*out_features, group_size]\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: shape '[-1, 128, 1536]' is invalid for input of size 18432"
     ]
    }
   ],
   "source": [
    "# check_quantization_efficiency.py\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def analyze_quantization(file_path):\n",
    "    data = torch.load(file_path)\n",
    "\n",
    "    if not isinstance(data, dict):\n",
    "        print(\"Error: Expected quantized layer dictionary\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nAnalyzing {file_path.name}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Extract parameters\n",
    "    qweight = data[\"qweight\"]  # shape: [in_features, out_features//8]\n",
    "    scales = data[\"scales\"]  # shape: [in_features//group_size, out_features]\n",
    "    qzeros = data[\"qzeros\"]  # shape: [in_features//group_size, out_features//8]\n",
    "\n",
    "    group_size = qweight.shape[0] // scales.shape[0]\n",
    "    print(f\"Group size: {group_size}\")\n",
    "    print(f\"Scales range: {scales.min().item():.4f} - {scales.max().item():.4f}\")\n",
    "\n",
    "    # Properly expand dimensions for broadcasting\n",
    "    scales = scales.view(\n",
    "        -1, group_size, scales.shape[-1]\n",
    "    )  # [groups, group_size, out_features]\n",
    "    scales = scales.transpose(1, 2)  # [groups, out_features, group_size]\n",
    "    scales = scales.reshape(-1, scales.shape[-1])  # [groups*out_features, group_size]\n",
    "\n",
    "    qzeros = qzeros.view(-1, 1, qzeros.shape[-1])  # [groups, 1, out_features//8]\n",
    "    qzeros = qzeros.expand(-1, group_size, -1)  # [groups, group_size, out_features//8]\n",
    "    qzeros = qzeros.reshape(-1, qzeros.shape[-1])  # [in_features, out_features//8]\n",
    "\n",
    "    # Dequantize sample weights\n",
    "    sample_qweight = qweight[:group_size]  # First group only for demo\n",
    "    sample_qzeros = qzeros[:group_size]\n",
    "    sample_scales = scales[:group_size]\n",
    "\n",
    "    dequant_weight = (sample_qweight - sample_qzeros) * sample_scales\n",
    "    print(\n",
    "        f\"Sample dequantized range: {dequant_weight.min().item():.4f} - {dequant_weight.max().item():.4f}\"\n",
    "    )\n",
    "\n",
    "    # Check 4-bit utilization\n",
    "    quantized_values = qweight.unique(sorted=True)\n",
    "    print(f\"Unique 4-bit values: {len(quantized_values)}/16\")\n",
    "    print(\n",
    "        f\"Value range: {quantized_values.min().item()} to {quantized_values.max().item()}\"\n",
    "    )\n",
    "\n",
    "    # Plot first group's weights\n",
    "\n",
    "    plt.hist(qweight[:group_size].cpu().flatten().numpy(), bins=16)\n",
    "    plt.title(\"4-bit Weight Values (First Group)\")\n",
    "    plt.xlabel(\"Quantized Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = Path(\"/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\")\n",
    "    layer_file = \"model.layers.0.self_attn.q_proj.pt\"\n",
    "    analyze_quantization(base_dir / layer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8c0a8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing model.layers.0.self_attn.q_proj.pt\n",
      "--------------------------------------------------\n",
      "Group size: 1536\n",
      "Scales range: 0.1963 - 3.5938\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1536) must match the size of tensor b (12) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     49\u001b[39m base_dir = Path(\u001b[33m\"\u001b[39m\u001b[33m/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m layer_file = \u001b[33m\"\u001b[39m\u001b[33mmodel.layers.0.self_attn.q_proj.pt\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Change as needed\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43manalyze_quantization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36manalyze_quantization\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScales range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscales.min().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscales.max().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Simulate dequantization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m dequant_weight = (\u001b[43mqweight\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mqzeros\u001b[49m) * scales\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     29\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDequantized weight range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdequant_weight.min().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdequant_weight.max().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Check 4-bit utilization\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (1536) must match the size of tensor b (12) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# check_quantization_efficiency.py\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def analyze_quantization(file_path):\n",
    "    data = torch.load(file_path)\n",
    "\n",
    "    if not isinstance(data, dict):\n",
    "        print(\"Error: Expected quantized layer dictionary (qweight, scales, qzeros)\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nAnalyzing {file_path.name}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Extract quantization parameters\n",
    "    qweight = data[\"qweight\"]\n",
    "    scales = data[\"scales\"]\n",
    "    qzeros = data[\"qzeros\"]\n",
    "    group_size = scales.shape[0] * (qweight.shape[0] // scales.shape[0])\n",
    "\n",
    "    print(f\"Group size: {group_size}\")\n",
    "    print(f\"Scales range: {scales.min().item():.4f} - {scales.max().item():.4f}\")\n",
    "\n",
    "    # Simulate dequantization\n",
    "    dequant_weight = (qweight - qzeros) * scales\n",
    "    print(\n",
    "        f\"Dequantized weight range: {dequant_weight.min().item():.4f} - {dequant_weight.max().item():.4f}\"\n",
    "    )\n",
    "\n",
    "    # Check 4-bit utilization\n",
    "    quantized_values = qweight.unique(sorted=True)\n",
    "    print(f\"Unique 4-bit values used: {len(quantized_values)}/16 possible\")\n",
    "    print(\n",
    "        f\"Value range: {quantized_values.min().item()} to {quantized_values.max().item()}\"\n",
    "    )\n",
    "\n",
    "    # Plot value distribution\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(qweight.cpu().flatten().numpy(), bins=50)\n",
    "    plt.title(f\"4-bit Weight Distribution\\n{file_path.name}\")\n",
    "    plt.xlabel(\"Quantized Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = Path(\"/home/xzhang/models/deepseek-awq-scrooge/quantized_layers\")\n",
    "    layer_file = \"model.layers.0.self_attn.q_proj.pt\"  # Change as needed\n",
    "    analyze_quantization(base_dir / layer_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128964e",
   "metadata": {},
   "source": [
    "# Inspect Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c40d0023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file filtered successfully. Output saved to /home/xzhang/dev/deepseek_local_runner/documents/filtered_rcs.log\n"
     ]
    }
   ],
   "source": [
    "def filter_log_file(input_file, output_file, keyword):\n",
    "    try:\n",
    "        with open(input_file, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        filtered_lines = [line for line in lines if keyword not in line]\n",
    "\n",
    "        with open(output_file, \"w\") as new_file:\n",
    "            new_file.writelines(filtered_lines)\n",
    "\n",
    "        print(f\"Log file filtered successfully. Output saved to {output_file}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Input file {input_file} not found.\")\n",
    "\n",
    "\n",
    "log_file = \"/home/xzhang/dev/deepseek_local_runner/documents/full_log_20250529_183204_resource.log\"\n",
    "filtered_log_file = \"/home/xzhang/dev/deepseek_local_runner/documents/filtered_rcs.log\"\n",
    "\n",
    "# Usage\n",
    "input_file = log_file\n",
    "output_file = filtered_log_file\n",
    "keyword = \"[AutoMonitor]\"\n",
    "\n",
    "filter_log_file(input_file, output_file, keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c9ef2",
   "metadata": {},
   "source": [
    "# Inspect Saftetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f61c892b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748f590eaf7e439a923cc7029e03bb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n    <div style=\"\\n        height: 400px;\\n        overflow: auto;\\n        background-color: bla‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "from pathlib import Path\n",
    "from project_config import DEEPSEEK_R1_DISTILL_QUANT_MODEL_DIR\n",
    "\n",
    "\n",
    "def inspect_safetensors_pretty(path: str | Path, max_preview: int = 5) -> list[str]:\n",
    "    \"\"\"\n",
    "    Load and format .safetensors inspection results as a list of printable strings.\n",
    "\n",
    "    Args:\n",
    "        path (str | Path): Path to the .safetensors file.\n",
    "        max_preview (int): Number of preview elements for small tensors.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: Cleaned list of lines describing tensor structure and sample values.\n",
    "    \"\"\"\n",
    "    path = Path(path).expanduser()\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "    state_dict = load_file(path)\n",
    "    lines = []\n",
    "    lines.append(f\"üîç Inspecting {path.name} ‚Äî {len(state_dict)} tensors found:\")\n",
    "\n",
    "    for name, tensor in state_dict.items():\n",
    "        line = f\"‚Ä¢ {name}: shape={tuple(tensor.shape)}, dtype={tensor.dtype}\"\n",
    "        if tensor.ndim <= 2 and tensor.numel() < 100:\n",
    "            preview = tensor.flatten()[:max_preview].tolist()\n",
    "            line += f\" | preview: {preview}\"\n",
    "        lines.append(line)\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "tensor_file = DEEPSEEK_R1_DISTILL_QUANT_MODEL_DIR / \"model.safetensors\"\n",
    "tensor_info = inspect_safetensors(tensor_file)\n",
    "\n",
    "show_scrollable(tensor_info, height=\"400px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d275800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Inspecting model.safetensors ‚Äî 588 tensors found:\n",
      "\n",
      "- model.layers.0.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.0.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.0.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.0.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.0.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.0.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.0.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.0.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.0.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.0.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.0.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.0.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.0.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.0.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.0.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.0.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.0.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.0.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.0.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.0.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.0.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.1.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.1.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.1.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.1.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.1.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.1.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.1.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.1.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.1.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.1.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.1.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.1.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.1.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.1.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.1.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.1.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.1.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.1.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.1.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.1.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.1.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.2.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.2.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.2.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.2.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.2.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.2.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.2.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.2.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.2.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.2.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.2.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.2.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.2.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.2.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.2.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.2.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.2.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.2.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.2.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.2.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.2.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.3.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.3.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.3.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.3.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.3.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.3.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.3.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.3.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.3.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.3.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.3.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.3.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.3.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.3.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.3.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.3.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.3.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.3.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.3.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.3.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.3.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.4.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.4.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.4.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.4.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.4.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.4.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.4.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.4.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.4.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.4.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.4.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.4.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.4.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.4.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.4.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.4.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.4.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.4.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.4.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.4.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.4.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.5.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.5.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.5.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.5.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.5.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.5.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.5.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.5.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.5.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.5.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.5.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.5.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.5.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.5.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.5.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.5.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.5.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.5.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.5.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.5.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.5.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.6.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.6.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.6.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.6.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.6.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.6.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.6.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.6.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.6.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.6.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.6.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.6.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.6.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.6.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.6.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.6.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.6.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.6.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.6.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.6.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.6.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.7.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.7.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.7.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.7.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.7.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.7.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.7.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.7.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.7.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.7.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.7.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.7.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.7.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.7.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.7.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.7.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.7.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.7.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.7.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.7.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.7.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.8.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.8.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.8.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.8.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.8.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.8.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.8.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.8.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.8.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.8.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.8.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.8.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.8.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.8.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.8.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.8.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.8.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.8.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.8.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.8.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.8.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.9.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.9.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.9.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.9.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.9.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.9.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.9.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.9.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.9.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.9.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.9.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.9.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.9.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.9.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.9.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.9.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.9.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.9.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.9.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.9.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.9.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.10.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.10.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.10.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.10.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.10.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.10.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.10.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.10.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.10.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.10.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.10.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.10.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.10.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.10.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.10.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.10.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.10.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.10.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.10.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.10.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.10.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.11.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.11.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.11.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.11.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.11.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.11.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.11.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.11.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.11.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.11.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.11.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.11.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.11.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.11.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.11.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.11.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.11.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.11.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.11.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.11.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.11.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.12.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.12.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.12.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.12.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.12.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.12.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.12.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.12.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.12.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.12.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.12.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.12.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.12.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.12.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.12.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.12.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.12.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.12.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.12.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.12.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.12.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.13.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.13.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.13.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.13.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.13.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.13.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.13.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.13.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.13.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.13.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.13.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.13.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.13.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.13.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.13.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.13.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.13.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.13.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.13.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.13.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.13.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.14.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.14.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.14.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.14.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.14.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.14.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.14.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.14.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.14.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.14.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.14.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.14.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.14.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.14.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.14.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.14.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.14.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.14.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.14.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.14.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.14.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.15.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.15.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.15.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.15.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.15.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.15.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.15.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.15.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.15.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.15.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.15.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.15.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.15.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.15.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.15.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.15.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.15.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.15.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.15.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.15.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.15.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.16.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.16.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.16.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.16.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.16.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.16.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.16.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.16.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.16.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.16.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.16.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.16.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.16.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.16.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.16.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.16.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.16.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.16.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.16.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.16.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.16.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.17.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.17.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.17.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.17.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.17.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.17.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.17.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.17.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.17.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.17.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.17.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.17.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.17.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.17.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.17.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.17.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.17.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.17.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.17.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.17.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.17.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.18.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.18.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.18.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.18.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.18.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.18.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.18.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.18.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.18.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.18.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.18.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.18.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.18.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.18.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.18.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.18.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.18.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.18.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.18.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.18.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.18.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.19.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.19.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.19.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.19.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.19.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.19.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.19.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.19.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.19.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.19.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.19.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.19.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.19.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.19.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.19.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.19.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.19.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.19.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.19.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.19.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.19.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.20.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.20.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.20.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.20.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.20.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.20.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.20.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.20.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.20.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.20.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.20.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.20.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.20.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.20.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.20.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.20.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.20.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.20.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.20.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.20.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.20.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.21.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.21.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.21.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.21.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.21.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.21.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.21.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.21.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.21.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.21.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.21.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.21.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.21.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.21.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.21.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.21.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.21.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.21.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.21.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.21.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.21.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.22.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.22.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.22.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.22.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.22.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.22.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.22.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.22.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.22.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.22.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.22.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.22.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.22.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.22.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.22.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.22.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.22.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.22.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.22.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.22.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.22.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.23.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.23.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.23.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.23.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.23.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.23.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.23.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.23.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.23.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.23.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.23.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.23.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.23.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.23.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.23.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.23.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.23.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.23.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.23.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.23.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.23.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.24.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.24.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.24.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.24.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.24.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.24.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.24.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.24.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.24.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.24.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.24.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.24.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.24.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.24.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.24.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.24.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.24.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.24.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.24.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.24.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.24.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.25.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.25.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.25.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.25.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.25.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.25.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.25.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.25.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.25.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.25.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.25.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.25.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.25.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.25.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.25.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.25.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.25.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.25.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.25.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.25.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.25.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.26.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.26.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.26.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.26.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.26.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.26.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.26.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.26.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.26.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.26.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.26.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.26.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.26.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.26.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.26.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.26.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.26.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.26.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.26.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.26.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.26.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.27.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "- model.layers.27.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "- model.layers.27.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "- model.layers.27.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.27.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.27.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.27.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "- model.layers.27.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "- model.layers.27.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "- model.layers.27.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.27.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.27.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.27.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "- model.layers.27.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "- model.layers.27.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "- model.layers.27.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "- model.layers.27.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "- model.layers.27.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "- model.layers.27.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "- model.layers.27.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "- model.layers.27.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from safetensors.torch import load_file\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def natural_key(text):\n",
    "    # Breaks text into chunks of digits and non-digits: \"layers.10\" ‚Üí [\"layers.\", 10]\n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r\"(\\d+)\", text)]\n",
    "\n",
    "\n",
    "def inspect_safetensors(path: str | Path, max_preview: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Print a readable, naturally sorted summary of a .safetensors file.\n",
    "\n",
    "    Args:\n",
    "        path (str | Path): Path to the .safetensors file.\n",
    "        max_preview (int): Max number of values to preview for small tensors.\n",
    "    \"\"\"\n",
    "    path = Path(path).expanduser()\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "    state_dict = load_file(path)\n",
    "    sorted_items = sorted(state_dict.items(), key=lambda x: natural_key(x[0]))\n",
    "\n",
    "    print(f\"\\nüîç Inspecting {path.name} ‚Äî {len(sorted_items)} tensors found:\\n\")\n",
    "\n",
    "    for name, tensor in sorted_items:\n",
    "        print(f\"- {name}: shape={tuple(tensor.shape)}, dtype={tensor.dtype}\")\n",
    "        if tensor.ndim <= 2 and tensor.numel() < 100:\n",
    "            print(f\"   preview: {tensor.flatten()[:max_preview].tolist()}\")\n",
    "\n",
    "\n",
    "tensor_file = Path(\n",
    "    \"~/models/deepseek-r1-distill-qwen-1.5b-awq-scrooge-4bit-g128/quantized_model/model.safetensors\"\n",
    ").expanduser()\n",
    "\n",
    "inspect_safetensors(tensor_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ad4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Missing critical weights: {'model.embed_tokens.weight', 'lm_head.weight'}\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "required_keys = {\"model.embed_tokens.weight\", \"lm_head.weight\"}  # Example keys\n",
    "tensor_file = Path(\n",
    "    \"~/models/deepseek-awq-scrooge/quantized_model/model.safetensors\"\n",
    ").expanduser()\n",
    "with safe_open(tensor_file, framework=\"pt\") as f:\n",
    "    missing = required_keys - set(f.keys())\n",
    "    if missing:\n",
    "        print(f\"WARNING: Missing critical weights: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3fcb4865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Total tensors: 588\n",
      "model.layers.0.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.0.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.0.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.0.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.0.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.0.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.0.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.0.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.0.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.0.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.0.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.0.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.0.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.0.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.0.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.0.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.0.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.0.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.0.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.0.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.0.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.1.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.1.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.1.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.1.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.1.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.1.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.1.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.1.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.1.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.1.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.1.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.1.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.1.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.1.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.1.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.1.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.1.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.1.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.1.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.1.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.1.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.10.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.10.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.10.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.10.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.10.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.10.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.10.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.10.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.10.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.10.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.10.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.10.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.10.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.10.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.10.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.10.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.10.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.10.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.10.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.10.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.10.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.11.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.11.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.11.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.11.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.11.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.11.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.11.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.11.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.11.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.11.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.11.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.11.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.11.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.11.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.11.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.11.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.11.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.11.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.11.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.11.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.11.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.12.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.12.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.12.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.12.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.12.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.12.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.12.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.12.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.12.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.12.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.12.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.12.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.12.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.12.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.12.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.12.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.12.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.12.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.12.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.12.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.12.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.13.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.13.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.13.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.13.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.13.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.13.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.13.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.13.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.13.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.13.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.13.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.13.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.13.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.13.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.13.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.13.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.13.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.13.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.13.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.13.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.13.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.14.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.14.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.14.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.14.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.14.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.14.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.14.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.14.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.14.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.14.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.14.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.14.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.14.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.14.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.14.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.14.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.14.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.14.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.14.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.14.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.14.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.15.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.15.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.15.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.15.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.15.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.15.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.15.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.15.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.15.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.15.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.15.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.15.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.15.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.15.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.15.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.15.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.15.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.15.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.15.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.15.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.15.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.16.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.16.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.16.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.16.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.16.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.16.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.16.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.16.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.16.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.16.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.16.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.16.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.16.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.16.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.16.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.16.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.16.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.16.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.16.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.16.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.16.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.17.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.17.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.17.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.17.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.17.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.17.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.17.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.17.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.17.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.17.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.17.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.17.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.17.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.17.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.17.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.17.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.17.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.17.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.17.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.17.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.17.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.18.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.18.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.18.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.18.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.18.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.18.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.18.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.18.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.18.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.18.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.18.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.18.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.18.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.18.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.18.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.18.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.18.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.18.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.18.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.18.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.18.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.19.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.19.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.19.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.19.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.19.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.19.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.19.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.19.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.19.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.19.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.19.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.19.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.19.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.19.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.19.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.19.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.19.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.19.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.19.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.19.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.19.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.2.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.2.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.2.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.2.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.2.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.2.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.2.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.2.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.2.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.2.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.2.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.2.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.2.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.2.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.2.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.2.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.2.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.2.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.2.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.2.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.2.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.20.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.20.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.20.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.20.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.20.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.20.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.20.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.20.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.20.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.20.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.20.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.20.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.20.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.20.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.20.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.20.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.20.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.20.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.20.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.20.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.20.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.21.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.21.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.21.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.21.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.21.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.21.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.21.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.21.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.21.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.21.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.21.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.21.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.21.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.21.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.21.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.21.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.21.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.21.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.21.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.21.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.21.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.22.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.22.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.22.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.22.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.22.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.22.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.22.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.22.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.22.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.22.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.22.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.22.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.22.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.22.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.22.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.22.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.22.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.22.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.22.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.22.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.22.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.23.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.23.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.23.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.23.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.23.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.23.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.23.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.23.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.23.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.23.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.23.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.23.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.23.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.23.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.23.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.23.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.23.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.23.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.23.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.23.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.23.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.24.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.24.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.24.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.24.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.24.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.24.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.24.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.24.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.24.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.24.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.24.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.24.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.24.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.24.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.24.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.24.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.24.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.24.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.24.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.24.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.24.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.25.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.25.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.25.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.25.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.25.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.25.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.25.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.25.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.25.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.25.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.25.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.25.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.25.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.25.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.25.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.25.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.25.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.25.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.25.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.25.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.25.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.26.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.26.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.26.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.26.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.26.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.26.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.26.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.26.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.26.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.26.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.26.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.26.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.26.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.26.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.26.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.26.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.26.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.26.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.26.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.26.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.26.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.27.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.27.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.27.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.27.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.27.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.27.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.27.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.27.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.27.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.27.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.27.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.27.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.27.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.27.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.27.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.27.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.27.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.27.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.27.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.27.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.27.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.3.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.3.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.3.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.3.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.3.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.3.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.3.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.3.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.3.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.3.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.3.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.3.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.3.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.3.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.3.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.3.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.3.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.3.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.3.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.3.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.3.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.4.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.4.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.4.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.4.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.4.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.4.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.4.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.4.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.4.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.4.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.4.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.4.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.4.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.4.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.4.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.4.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.4.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.4.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.4.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.4.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.4.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.5.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.5.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.5.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.5.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.5.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.5.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.5.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.5.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.5.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.5.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.5.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.5.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.5.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.5.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.5.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.5.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.5.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.5.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.5.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.5.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.5.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.6.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.6.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.6.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.6.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.6.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.6.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.6.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.6.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.6.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.6.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.6.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.6.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.6.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.6.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.6.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.6.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.6.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.6.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.6.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.6.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.6.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.7.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.7.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.7.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.7.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.7.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.7.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.7.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.7.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.7.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.7.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.7.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.7.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.7.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.7.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.7.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.7.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.7.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.7.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.7.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.7.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.7.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.8.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.8.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.8.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.8.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.8.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.8.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.8.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.8.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.8.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.8.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.8.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.8.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.8.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.8.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.8.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.8.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.8.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.8.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.8.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.8.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.8.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.9.mlp.down_proj.qweight: shape=(8960, 192), dtype=torch.int32\n",
      "model.layers.9.mlp.down_proj.qzeros: shape=(70, 192), dtype=torch.int32\n",
      "model.layers.9.mlp.down_proj.scales: shape=(70, 1536), dtype=torch.float16\n",
      "model.layers.9.mlp.gate_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.9.mlp.gate_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.9.mlp.gate_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.9.mlp.up_proj.qweight: shape=(1536, 1120), dtype=torch.int32\n",
      "model.layers.9.mlp.up_proj.qzeros: shape=(12, 1120), dtype=torch.int32\n",
      "model.layers.9.mlp.up_proj.scales: shape=(12, 8960), dtype=torch.float16\n",
      "model.layers.9.self_attn.k_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.9.self_attn.k_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.9.self_attn.k_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.9.self_attn.k_proj.scales: shape=(12, 256), dtype=torch.float16\n",
      "model.layers.9.self_attn.q_proj.bias: shape=(1536,), dtype=torch.float16\n",
      "model.layers.9.self_attn.q_proj.qweight: shape=(1536, 192), dtype=torch.int32\n",
      "model.layers.9.self_attn.q_proj.qzeros: shape=(12, 192), dtype=torch.int32\n",
      "model.layers.9.self_attn.q_proj.scales: shape=(12, 1536), dtype=torch.float16\n",
      "model.layers.9.self_attn.v_proj.bias: shape=(256,), dtype=torch.float16\n",
      "model.layers.9.self_attn.v_proj.qweight: shape=(1536, 32), dtype=torch.int32\n",
      "model.layers.9.self_attn.v_proj.qzeros: shape=(12, 32), dtype=torch.int32\n",
      "model.layers.9.self_attn.v_proj.scales: shape=(12, 256), dtype=torch.float16\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "tensor_file = Path(\n",
    "    \"~/models/deepseek-r1-distill-qwen-1.5b-awq-scrooge-4bit-g128/quantized_model/model.safetensors\"\n",
    ").expanduser()\n",
    "\n",
    "with safe_open(tensor_file, framework=\"pt\") as f:\n",
    "    print(f\"\\nüîç Total tensors: {len(f.keys())}\")\n",
    "    for key in f.keys():\n",
    "        tensor = f.get_tensor(key)\n",
    "        print(f\"{key}: shape={tuple(tensor.shape)}, dtype={tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1eb8c997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Loaded config from: /home/xzhang/models/deepseek-r1-distill-qwen-1.5b-awq-scrooge-4bit-g128/quantized_model/config.json\n",
      "architectures: ['Qwen2ForCausalLM'] (type: <class 'list'>)\n",
      "attention_dropout: 0.0 (type: <class 'float'>)\n",
      "bos_token_id: 151643 (type: <class 'int'>)\n",
      "eos_token_id: 151643 (type: <class 'int'>)\n",
      "hidden_act: silu (type: <class 'str'>)\n",
      "hidden_size: 1536 (type: <class 'int'>)\n",
      "initializer_range: 0.02 (type: <class 'float'>)\n",
      "intermediate_size: 8960 (type: <class 'int'>)\n",
      "max_position_embeddings: 131072 (type: <class 'int'>)\n",
      "max_window_layers: 21 (type: <class 'int'>)\n",
      "model_type: qwen2 (type: <class 'str'>)\n",
      "num_attention_heads: 12 (type: <class 'int'>)\n",
      "num_hidden_layers: 28 (type: <class 'int'>)\n",
      "num_key_value_heads: 2 (type: <class 'int'>)\n",
      "quantization_config.q_group_size: 128 (type: <class 'int'>)\n",
      "quantization_config.version: gemm (type: <class 'str'>)\n",
      "quantization_config.w_bit: 4 (type: <class 'int'>)\n",
      "quantization_config.zero_point: True (type: <class 'bool'>)\n",
      "rms_norm_eps: 1e-06 (type: <class 'float'>)\n",
      "rope_scaling: None (type: <class 'NoneType'>)\n",
      "rope_theta: 10000 (type: <class 'int'>)\n",
      "sliding_window: None (type: <class 'NoneType'>)\n",
      "tie_word_embeddings: False (type: <class 'bool'>)\n",
      "torch_dtype: bfloat16 (type: <class 'str'>)\n",
      "transformers_version: 4.46.0 (type: <class 'str'>)\n",
      "use_cache: False (type: <class 'bool'>)\n",
      "use_mrope: False (type: <class 'bool'>)\n",
      "use_sliding_window: False (type: <class 'bool'>)\n",
      "vocab_size: 151936 (type: <class 'int'>)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def inspect_config_types(config_path: str | Path) -> None:\n",
    "    config_path = Path(config_path).expanduser()\n",
    "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    def print_types(d, prefix=\"\"):\n",
    "        for k, v in d.items():\n",
    "            full_key = f\"{prefix}.{k}\" if prefix else k\n",
    "            if isinstance(v, dict):\n",
    "                print_types(v, prefix=full_key)\n",
    "            else:\n",
    "                print(f\"{full_key}: {v} (type: {type(v)})\")\n",
    "\n",
    "    print(f\"\\nüìÅ Loaded config from: {config_path}\")\n",
    "    print_types(config)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "inspect_config_types(\n",
    "    \"~/models/deepseek-r1-distill-qwen-1.5b-awq-scrooge-4bit-g128/quantized_model/config.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47498949",
   "metadata": {},
   "source": [
    "## Check o_proj layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f4b5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "tensor_file = Path(\n",
    "    \"~/models/deepseek-r1-distill-qwen-1.5b-awq-scrooge-4bit-g128/quantized_model/model.safetensors\"\n",
    ").expanduser()\n",
    "tensor_dict = load_file(tensor_file)\n",
    "\n",
    "layers = [f\"model.layers.{i}.self_attn.o_proj.weight\" for i in range(28)]\n",
    "\n",
    "for name in layers:\n",
    "    if name not in tensor_dict:\n",
    "        print(f\"‚ùå Missing: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fde1608c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Missing weights:\n",
      "  - model.layers.0.mlp.gate_proj.weight\n",
      "  - model.layers.0.mlp.up_proj.weight\n",
      "  - model.layers.0.mlp.down_proj.weight\n",
      "  - model.layers.1.mlp.gate_proj.weight\n",
      "  - model.layers.1.mlp.up_proj.weight\n",
      "  - model.layers.1.mlp.down_proj.weight\n",
      "  - model.layers.2.mlp.gate_proj.weight\n",
      "  - model.layers.2.mlp.up_proj.weight\n",
      "  - model.layers.2.mlp.down_proj.weight\n",
      "  - model.layers.3.mlp.gate_proj.weight\n",
      "  - model.layers.3.mlp.up_proj.weight\n",
      "  - model.layers.3.mlp.down_proj.weight\n",
      "  - model.layers.4.mlp.gate_proj.weight\n",
      "  - model.layers.4.mlp.up_proj.weight\n",
      "  - model.layers.4.mlp.down_proj.weight\n",
      "  - model.layers.5.mlp.gate_proj.weight\n",
      "  - model.layers.5.mlp.up_proj.weight\n",
      "  - model.layers.5.mlp.down_proj.weight\n",
      "  - model.layers.6.mlp.gate_proj.weight\n",
      "  - model.layers.6.mlp.up_proj.weight\n",
      "  - model.layers.6.mlp.down_proj.weight\n",
      "  - model.layers.7.mlp.gate_proj.weight\n",
      "  - model.layers.7.mlp.up_proj.weight\n",
      "  - model.layers.7.mlp.down_proj.weight\n",
      "  - model.layers.8.mlp.gate_proj.weight\n",
      "  - model.layers.8.mlp.up_proj.weight\n",
      "  - model.layers.8.mlp.down_proj.weight\n",
      "  - model.layers.9.mlp.gate_proj.weight\n",
      "  - model.layers.9.mlp.up_proj.weight\n",
      "  - model.layers.9.mlp.down_proj.weight\n",
      "  - model.layers.10.mlp.gate_proj.weight\n",
      "  - model.layers.10.mlp.up_proj.weight\n",
      "  - model.layers.10.mlp.down_proj.weight\n",
      "  - model.layers.11.mlp.gate_proj.weight\n",
      "  - model.layers.11.mlp.up_proj.weight\n",
      "  - model.layers.11.mlp.down_proj.weight\n",
      "  - model.layers.12.mlp.gate_proj.weight\n",
      "  - model.layers.12.mlp.up_proj.weight\n",
      "  - model.layers.12.mlp.down_proj.weight\n",
      "  - model.layers.13.mlp.gate_proj.weight\n",
      "  - model.layers.13.mlp.up_proj.weight\n",
      "  - model.layers.13.mlp.down_proj.weight\n",
      "  - model.layers.14.mlp.gate_proj.weight\n",
      "  - model.layers.14.mlp.up_proj.weight\n",
      "  - model.layers.14.mlp.down_proj.weight\n",
      "  - model.layers.15.mlp.gate_proj.weight\n",
      "  - model.layers.15.mlp.up_proj.weight\n",
      "  - model.layers.15.mlp.down_proj.weight\n",
      "  - model.layers.16.mlp.gate_proj.weight\n",
      "  - model.layers.16.mlp.up_proj.weight\n",
      "  - model.layers.16.mlp.down_proj.weight\n",
      "  - model.layers.17.mlp.gate_proj.weight\n",
      "  - model.layers.17.mlp.up_proj.weight\n",
      "  - model.layers.17.mlp.down_proj.weight\n",
      "  - model.layers.18.mlp.gate_proj.weight\n",
      "  - model.layers.18.mlp.up_proj.weight\n",
      "  - model.layers.18.mlp.down_proj.weight\n",
      "  - model.layers.19.mlp.gate_proj.weight\n",
      "  - model.layers.19.mlp.up_proj.weight\n",
      "  - model.layers.19.mlp.down_proj.weight\n",
      "  - model.layers.20.mlp.gate_proj.weight\n",
      "  - model.layers.20.mlp.up_proj.weight\n",
      "  - model.layers.20.mlp.down_proj.weight\n",
      "  - model.layers.21.mlp.gate_proj.weight\n",
      "  - model.layers.21.mlp.up_proj.weight\n",
      "  - model.layers.21.mlp.down_proj.weight\n",
      "  - model.layers.22.mlp.gate_proj.weight\n",
      "  - model.layers.22.mlp.up_proj.weight\n",
      "  - model.layers.22.mlp.down_proj.weight\n",
      "  - model.layers.23.mlp.gate_proj.weight\n",
      "  - model.layers.23.mlp.up_proj.weight\n",
      "  - model.layers.23.mlp.down_proj.weight\n",
      "  - model.layers.24.mlp.gate_proj.weight\n",
      "  - model.layers.24.mlp.up_proj.weight\n",
      "  - model.layers.24.mlp.down_proj.weight\n",
      "  - model.layers.25.mlp.gate_proj.weight\n",
      "  - model.layers.25.mlp.up_proj.weight\n",
      "  - model.layers.25.mlp.down_proj.weight\n",
      "  - model.layers.26.mlp.gate_proj.weight\n",
      "  - model.layers.26.mlp.up_proj.weight\n",
      "  - model.layers.26.mlp.down_proj.weight\n",
      "  - model.layers.27.mlp.gate_proj.weight\n",
      "  - model.layers.27.mlp.up_proj.weight\n",
      "  - model.layers.27.mlp.down_proj.weight\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to your model.safetensors file\n",
    "tensor_file = Path(\n",
    "    \"~/models/deepseek-r1-distill-qwen-1.5b-awq-scrooge-4bit-g128/quantized_model/model.safetensors\"\n",
    ").expanduser()\n",
    "\n",
    "# Load the tensor dictionary\n",
    "tensor_dict = load_file(tensor_file)\n",
    "\n",
    "# Build expected full-precision MLP layer weights\n",
    "expected_fp_weights = [\n",
    "    f\"model.layers.{i}.{proj}.weight\"\n",
    "    for i in range(28)\n",
    "    for proj in [\"mlp.gate_proj\", \"mlp.up_proj\", \"mlp.down_proj\"]\n",
    "]\n",
    "\n",
    "# Print missing ones\n",
    "missing = [name for name in expected_fp_weights if name not in tensor_dict]\n",
    "print(\n",
    "    \"‚úÖ All expected MLP weights are present.\" if not missing else \"‚ùå Missing weights:\"\n",
    ")\n",
    "for name in missing:\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9b21d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Top-level keys:\n",
      "- architectures\n",
      "- attention_dropout\n",
      "- bos_token_id\n",
      "- eos_token_id\n",
      "- hidden_act\n",
      "- hidden_size\n",
      "- initializer_range\n",
      "- intermediate_size\n",
      "- max_position_embeddings\n",
      "- max_window_layers\n",
      "- model_type\n",
      "- num_attention_heads\n",
      "- num_hidden_layers\n",
      "- num_key_value_heads\n",
      "- quantization_config\n",
      "- rms_norm_eps\n",
      "- rope_scaling\n",
      "- rope_theta\n",
      "- sliding_window\n",
      "- tie_word_embeddings\n",
      "- torch_dtype\n",
      "- transformers_version\n",
      "- use_cache\n",
      "- use_mrope\n",
      "- use_sliding_window\n",
      "- vocab_size\n",
      "\n",
      "üîç quantization_config block:\n",
      "{'q_group_size': 128, 'version': 'gemm', 'w_bit': 4, 'zero_point': True}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "config_path = Path(\n",
    "    \"/home/xzhang/models/deepseek-r1-distill-qwen-1.5b-awq-scrooge-4bit-g128/quantized_model/config.json\"\n",
    ")\n",
    "with config_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"\\nüîç Top-level keys:\")\n",
    "for k in data:\n",
    "    print(\"-\", k)\n",
    "\n",
    "print(\"\\nüîç quantization_config block:\")\n",
    "print(data.get(\"quantization_config\", \"‚ùå Not found\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4e43be",
   "metadata": {},
   "source": [
    "# Inspect Hansen Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4757041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6d2745b3da48d0b1d288dec5e13c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/xzhang/models/casperhansen-deepseek-r1-distill-qwen-1.5b-awq'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "model_name = \"casperhansen/deepseek-r1-distill-qwen-1.5b-awq\"\n",
    "local_dir = Path(\"~/models/casperhansen-deepseek-r1-distill-qwen-1.5b-awq\").expanduser()\n",
    "\n",
    "snapshot_download(repo_id=model_name, local_dir=str(local_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b7df16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7974743c9d4a1e96126838ef0cfdb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n    <div style=\"\\n        height: 400px;\\n        overflow: auto;\\n        background-color: bla‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_dir = Path(\"~/models/casperhansen-deepseek-r1-distill-qwen-1.5b-awq\").expanduser()\n",
    "tensor_file = model_dir / \"model.safetensors\"\n",
    "\n",
    "# Get output as string\n",
    "tensor_info = inspect_safetensors(tensor_file)\n",
    "\n",
    "# Display in scrollable box\n",
    "show_scrollable(tensor_info, height=\"400px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53072e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8960 / 70"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
